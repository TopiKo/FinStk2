{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from df_utils import get_companies_list, get_X_y\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, \\\n",
    "                            precision_score, accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataframe and companies with not too many nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, companies = get_companies_list(2)\n",
    "# learner history parameters\n",
    "nhist = 10\n",
    "nfut = 2\n",
    "totHist = int(3*365)\n",
    "\n",
    "comp_dict = {}\n",
    "for i, comp in enumerate(companies):\n",
    "    comp_dict[comp] = get_X_y(df, comp, nfut, nhist, totHist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop some columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['offer_end_-01' 'offer_end_-02' 'offer_end_-03' 'offer_end_-04'\n",
      " 'offer_end_-05' 'offer_end_-06' 'offer_end_-07' 'offer_end_-08'\n",
      " 'offer_end_-09' 'offer_end_-10' 'offer_buy_-01' 'offer_buy_-02'\n",
      " 'offer_buy_-03' 'offer_buy_-04' 'offer_buy_-05' 'offer_buy_-06'\n",
      " 'offer_buy_-07' 'offer_buy_-08' 'offer_buy_-09' 'offer_buy_-10'\n",
      " 'offer_sell_-01' 'offer_sell_-02' 'offer_sell_-03' 'offer_sell_-04'\n",
      " 'offer_sell_-05' 'offer_sell_-06' 'offer_sell_-07' 'offer_sell_-08'\n",
      " 'offer_sell_-09' 'offer_sell_-10' 'sales_low_-01' 'sales_low_-02'\n",
      " 'sales_low_-03' 'sales_low_-04' 'sales_low_-05' 'sales_low_-06'\n",
      " 'sales_low_-07' 'sales_low_-08' 'sales_low_-09' 'sales_low_-10'\n",
      " 'sales_high_-01' 'sales_high_-02' 'sales_high_-03' 'sales_high_-04'\n",
      " 'sales_high_-05' 'sales_high_-06' 'sales_high_-07' 'sales_high_-08'\n",
      " 'sales_high_-09' 'sales_high_-10' 'change_Me_-01' 'change_Me_-02'\n",
      " 'change_Me_-03' 'change_Me_-04' 'change_Me_-05' 'change_Me_-06'\n",
      " 'change_Me_-07' 'change_Me_-08' 'change_Me_-09' 'change_Me_-10'\n",
      " 'c_slow_-01' 'c_slow_-02' 'c_slow_-03' 'c_slow_-04' 'c_slow_-05'\n",
      " 'c_slow_-06' 'c_slow_-07' 'c_slow_-08' 'c_slow_-09' 'c_slow_-10'\n",
      " 'c_slow_%_-01' 'c_slow_%_-02' 'c_slow_%_-03' 'c_slow_%_-04' 'c_slow_%_-05'\n",
      " 'c_slow_%_-06' 'c_slow_%_-07' 'c_slow_%_-08' 'c_slow_%_-09' 'c_slow_%_-10'\n",
      " 'c_shigh_-01' 'c_shigh_-02' 'c_shigh_-03' 'c_shigh_-04' 'c_shigh_-05'\n",
      " 'c_shigh_-06' 'c_shigh_-07' 'c_shigh_-08' 'c_shigh_-09' 'c_shigh_-10'\n",
      " 'c_shigh_%_-01' 'c_shigh_%_-02' 'c_shigh_%_-03' 'c_shigh_%_-04'\n",
      " 'c_shigh_%_-05' 'c_shigh_%_-06' 'c_shigh_%_-07' 'c_shigh_%_-08'\n",
      " 'c_shigh_%_-09' 'c_shigh_%_-10' 'c_oend_-01' 'c_oend_-02' 'c_oend_-03'\n",
      " 'c_oend_-04' 'c_oend_-05' 'c_oend_-06' 'c_oend_-07' 'c_oend_-08'\n",
      " 'c_oend_-09' 'c_oend_-10' 'c_oend_%_-01' 'c_oend_%_-02' 'c_oend_%_-03'\n",
      " 'c_oend_%_-04' 'c_oend_%_-05' 'c_oend_%_-06' 'c_oend_%_-07' 'c_oend_%_-08'\n",
      " 'c_oend_%_-09' 'c_oend_%_-10']\n",
      "['offer_end_change' 'sale_low_change+1' 'sale_low_change'\n",
      " 'sale_high_change']\n",
      "['offer_end_change' 'sale_low_change+1' 'sale_low_change' 'offer_end_prev'\n",
      " 'sales_low_000' 'sales_high_000' 'sales_low_001' 'sales_high_001'\n",
      " 'offer_end_001']\n"
     ]
    }
   ],
   "source": [
    "X_orig, y, ysim = comp_dict[comp]\n",
    "print(X_orig.columns.values)\n",
    "print(y.columns.values)\n",
    "print(ysim.columns.values)\n",
    "\n",
    "include = ['c_oend_%', 'c_slow_%', 'c_shigh_%', 'change_Me', 'offer_sell_', 'offer_buy_'] #['c_shigh_', 'c_slow_', 'offer_sell_', 'offer_buy_', 'sales_low_', 'sales_high_']\n",
    "cols_keep = [col for col in X_orig.columns if col[:-4] in include] \n",
    "y_cols = ['offer_end_change', 'sale_low_change', 'sale_high_change']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot pictures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_sim(comp, ysim, ndays, *args):\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize = (12,6))\n",
    "    x = pd.to_datetime(ysim.index, format = '%d.%m.%Y')[:ndays]\n",
    "    yl = ysim['sales_low_000'].values[:ndays]\n",
    "    yh = ysim['sales_high_000'].values[:ndays]\n",
    "    #y = ysim['offer_end_prev'].values[:ndays]\n",
    "    \n",
    "    #plt.plot_date(x,y, linestyle = '-', marker = None)\n",
    "    plt.fill_between(x,yl,yh, linestyle = '-')\n",
    "    plt.ylabel('Sales lowest to highest filled')\n",
    "    #[plt.gca().axvline(xi, alpha = .1) for xi in x]\n",
    "    \n",
    "    if len(args) == 3:\n",
    "        pred, truth, col = [arg[:ndays] for arg in args]\n",
    "        \n",
    "        correct = pred & truth\n",
    "        fp = pred & np.logical_not(truth)\n",
    "        \n",
    "        plt.scatter(x[correct], yh[correct], s = 40, alpha = .7, \n",
    "                    c = 'green', label = col + ' correct')\n",
    "        plt.scatter(x[truth], yh[truth], s = 20, c = 'red', alpha = .2,\n",
    "                    label = col + ' true')\n",
    "        \n",
    "    else:    \n",
    "        plt.twinx()\n",
    "        y2 = ysim['offer_end_change']*100\n",
    "        plt.plot_date(x,y2, linestyle = '-', marker = None, color = 'red')\n",
    "        plt.ylabel('Offer end percentage change')\n",
    "    \n",
    "    plt.legend(frameon = False)\n",
    "    plt.title(comp, fontsize = 14)\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make estimator pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([('pol', PolynomialFeatures(degree = 2, interaction_only = True)),\n",
    "                    ('var', VarianceThreshold()),\n",
    "                    ('scale', StandardScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('rf', RandomForestClassifier())]) \n",
    "\n",
    "params_rf = [{'pca__n_components': np.arange(40,100,10),\n",
    "                'rf__max_features': np.arange(5,30,5),\n",
    "                'rf__max_depth': [5,10,20],\n",
    "                'rf__n_estimators': [20,50,100]}]\n",
    "\n",
    "pipe_gbm = Pipeline([('pol', PolynomialFeatures(degree = 2, interaction_only = True)),\n",
    "                     ('var', VarianceThreshold()),\n",
    "                     ('scale', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "                     ('gbm', GradientBoostingClassifier())]) \n",
    "\n",
    "params_gbm = [{'pca__n_components': np.arange(40,100,10),\n",
    "                'rf__max_features': np.arange(5,30,5),\n",
    "                'rf__max_depth': [5,10,20],\n",
    "                'rf__n_estimators': [20,50,100]}]\n",
    "\n",
    "\n",
    "def get_pipe(key):\n",
    "    if key == 'rf':\n",
    "        return pipe_rf, params_rf\n",
    "    elif key == 'gbm':\n",
    "        return pipe_gbm, params_gbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make custom fit for each company:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_estimator(comp, y, threshold, pipe, params, ntest = 50, metric = 'roc_auc'):\n",
    "    \n",
    "    splitter = StratifiedKFold(n_splits = 5, shuffle = True) #, random_state = 0)\n",
    "    X,_,ysim = comp_dict[comp]\n",
    "    X = X[cols_keep]\n",
    "    \n",
    "    y_bin = threshold < y\n",
    "    \n",
    "    X_test, y_test = X[:ntest], y_bin[:ntest]\n",
    "    X_train, y_train = X[ntest:], y_bin[ntest:]\n",
    "    Xy = [X_train, X_test, y_train, y_test, ysim, y_bin]\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(pipe, params, scoring = metric, n_jobs = 5, \n",
    "                        cv = splitter, verbose = 1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return Xy, grid.best_estimator_, grid.best_params_, grid.best_score_\n",
    "\n",
    "\n",
    "def get_scores(y_pred_train, y_pred_test, y_pred_train_p, \n",
    "               y_pred_test_p, y_train, y_test, show_report = False):\n",
    "    try:\n",
    "        roc_auc_test = roc_auc_score(y_test, y_pred_test_p)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        roc_auc_test = -1\n",
    "    \n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    \n",
    "    if show_report:\n",
    "        print('Train set classification')\n",
    "        print(classification_report(y_train, y_pred_train, target_names = ['not rise', 'rise']))\n",
    "        print(confusion_matrix(y_train, y_pred_train))\n",
    "        print('Train roc_auc = {:.3f}'.format(roc_auc_score(y_train, y_pred_train_p)))\n",
    "        print('\\nTest set classification')\n",
    "        print(classification_report(y_test, y_pred_test, target_names = ['not rise', 'rise']))\n",
    "        print(confusion_matrix(y_test, y_pred_test))\n",
    "        print('Test roc_auc = {:.3f}\\n'.format(roc_auc_test))\n",
    "    \n",
    "    return roc_auc_test, precision_test\n",
    "\n",
    "def get_prediction(Xy, estimator, show_report = False):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Xy[:4]\n",
    "    y_pred_train = estimator.predict(X_train)\n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "    y_pred_train_p = estimator.predict_proba(X_train)[:,1]\n",
    "    y_pred_test_p = estimator.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    \n",
    "    return y_pred_train, y_pred_test, y_pred_train_p, y_pred_test_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed the pipe to fit for each company and collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktia Pankki A   offer_end_change\n",
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=5)]: Done 440 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=5)]: Done 790 tasks      | elapsed:  4.2min\n"
     ]
    }
   ],
   "source": [
    "def fit_and_report(companies, key = 'rf', ntest = 100, show = False):\n",
    "    \n",
    "    thres = {'offer_end_change':.01, \n",
    "             'sale_low_change+1':.0,\n",
    "             'sale_low_change':.01,\n",
    "             'sale_high_change':.01}\n",
    "    \n",
    "    pipe, params = get_pipe(key)\n",
    "    try:\n",
    "        results_dict = np.load('opm_params_{}.npy'.format(key)).item()        \n",
    "    except FileNotFoundError:\n",
    "        results_dict = {}\n",
    "    \n",
    "    for comp in companies:\n",
    "        y = comp_dict[comp][1]\n",
    "        for col in y.columns.values:\n",
    "            try:\n",
    "                results_dict[comp][col]\n",
    "            except KeyError:\n",
    "                \n",
    "                \n",
    "                print(comp, ' ', col)\n",
    "\n",
    "                X,_,ysim = comp_dict[comp]\n",
    "                X = X[cols_keep]\n",
    "\n",
    "                Xy, estimator_r, params_opm_r, score_r \\\n",
    "                    = comp_estimator(comp, y[col].values,\n",
    "                                     thres[col], pipe, params,\n",
    "                                     ntest = ntest,\n",
    "                                     metric = 'roc_auc')\n",
    "\n",
    "                y_pred_train, y_pred_test, y_pred_train_p, y_pred_test_p \\\n",
    "                    = get_prediction(Xy, estimator_r)\n",
    "\n",
    "                roc_auc, precision = get_scores(y_pred_train, \n",
    "                                                y_pred_test, \n",
    "                                                y_pred_train_p, \n",
    "                                                y_pred_test_p, \n",
    "                                                Xy[2], Xy[3], \n",
    "                                                show_report = show)\n",
    "\n",
    "                if show:\n",
    "                    print(params_opm_r)\n",
    "                    y_pred_tot = np.concatenate((y_pred_test, \n",
    "                                                 y_pred_train))\n",
    "                    plot_sim(comp, Xy[4], ntest*4, y_pred_tot, \n",
    "                             Xy[5], col)\n",
    "\n",
    "\n",
    "                col_dict = {col: {'roc_auc':roc_auc, \n",
    "                                  'precision':precision,\n",
    "                                  'threshold':thres[col],\n",
    "                                  'opm_params':params_opm_r}}\n",
    "                try:\n",
    "                    results_dict[comp].update(col_dict)\n",
    "                except KeyError:\n",
    "                    results_dict[comp] = col_dict\n",
    "                    \n",
    "                print(results_dict[comp])\n",
    "        np.save('opm_params_{}'.format(key), results_dict)\n",
    "    return results_dict\n",
    "\n",
    "fit_companies = companies\n",
    "converged = False\n",
    "results_dict = fit_and_report(fit_companies, 'rf', ntest = 50, show = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then test the obtained results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimal parameters:\n",
    "key = 'rf'\n",
    "opm_params = np.load('opm_params_{}.npy'.format(key)).item()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
