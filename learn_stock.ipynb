{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from df_utils import get_companies_list, get_X_y\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, \\\n",
    "                            precision_score, accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataframe and companies with not too many nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, companies = get_companies_list(2)\n",
    "# learner history parameters\n",
    "nhist = 10\n",
    "nfut = 2\n",
    "totHist = int(3*365)\n",
    "\n",
    "comp_dict = {}\n",
    "for i, comp in enumerate(companies):\n",
    "    comp_dict[comp] = get_X_y(df, comp, nfut, nhist, totHist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop some columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['offer_end_-01' 'offer_end_-02' 'offer_end_-03' 'offer_end_-04'\n",
      " 'offer_end_-05' 'offer_end_-06' 'offer_end_-07' 'offer_end_-08'\n",
      " 'offer_end_-09' 'offer_end_-10' 'offer_buy_-01' 'offer_buy_-02'\n",
      " 'offer_buy_-03' 'offer_buy_-04' 'offer_buy_-05' 'offer_buy_-06'\n",
      " 'offer_buy_-07' 'offer_buy_-08' 'offer_buy_-09' 'offer_buy_-10'\n",
      " 'offer_sell_-01' 'offer_sell_-02' 'offer_sell_-03' 'offer_sell_-04'\n",
      " 'offer_sell_-05' 'offer_sell_-06' 'offer_sell_-07' 'offer_sell_-08'\n",
      " 'offer_sell_-09' 'offer_sell_-10' 'sales_low_-01' 'sales_low_-02'\n",
      " 'sales_low_-03' 'sales_low_-04' 'sales_low_-05' 'sales_low_-06'\n",
      " 'sales_low_-07' 'sales_low_-08' 'sales_low_-09' 'sales_low_-10'\n",
      " 'sales_high_-01' 'sales_high_-02' 'sales_high_-03' 'sales_high_-04'\n",
      " 'sales_high_-05' 'sales_high_-06' 'sales_high_-07' 'sales_high_-08'\n",
      " 'sales_high_-09' 'sales_high_-10' 'change_Me_-01' 'change_Me_-02'\n",
      " 'change_Me_-03' 'change_Me_-04' 'change_Me_-05' 'change_Me_-06'\n",
      " 'change_Me_-07' 'change_Me_-08' 'change_Me_-09' 'change_Me_-10'\n",
      " 'c_slow_-01' 'c_slow_-02' 'c_slow_-03' 'c_slow_-04' 'c_slow_-05'\n",
      " 'c_slow_-06' 'c_slow_-07' 'c_slow_-08' 'c_slow_-09' 'c_slow_-10'\n",
      " 'c_slow_%_-01' 'c_slow_%_-02' 'c_slow_%_-03' 'c_slow_%_-04' 'c_slow_%_-05'\n",
      " 'c_slow_%_-06' 'c_slow_%_-07' 'c_slow_%_-08' 'c_slow_%_-09' 'c_slow_%_-10'\n",
      " 'c_shigh_-01' 'c_shigh_-02' 'c_shigh_-03' 'c_shigh_-04' 'c_shigh_-05'\n",
      " 'c_shigh_-06' 'c_shigh_-07' 'c_shigh_-08' 'c_shigh_-09' 'c_shigh_-10'\n",
      " 'c_shigh_%_-01' 'c_shigh_%_-02' 'c_shigh_%_-03' 'c_shigh_%_-04'\n",
      " 'c_shigh_%_-05' 'c_shigh_%_-06' 'c_shigh_%_-07' 'c_shigh_%_-08'\n",
      " 'c_shigh_%_-09' 'c_shigh_%_-10' 'c_oend_-01' 'c_oend_-02' 'c_oend_-03'\n",
      " 'c_oend_-04' 'c_oend_-05' 'c_oend_-06' 'c_oend_-07' 'c_oend_-08'\n",
      " 'c_oend_-09' 'c_oend_-10' 'c_oend_%_-01' 'c_oend_%_-02' 'c_oend_%_-03'\n",
      " 'c_oend_%_-04' 'c_oend_%_-05' 'c_oend_%_-06' 'c_oend_%_-07' 'c_oend_%_-08'\n",
      " 'c_oend_%_-09' 'c_oend_%_-10']\n",
      "['offer_end_change' 'sale_low_change+1' 'sale_low_change'\n",
      " 'sale_high_change']\n",
      "['offer_end_change' 'sale_low_change+1' 'sale_low_change' 'offer_end_prev'\n",
      " 'sales_low_000' 'sales_high_000' 'sales_low_001' 'sales_high_001'\n",
      " 'offer_end_001']\n"
     ]
    }
   ],
   "source": [
    "X_orig, y, ysim = comp_dict[comp]\n",
    "print(X_orig.columns.values)\n",
    "print(y.columns.values)\n",
    "print(ysim.columns.values)\n",
    "\n",
    "include = ['c_oend_%', 'c_slow_%', 'c_shigh_%', 'change_Me', 'offer_sell_', 'offer_buy_'] #['c_shigh_', 'c_slow_', 'offer_sell_', 'offer_buy_', 'sales_low_', 'sales_high_']\n",
    "cols_keep = [col for col in X_orig.columns if col[:-4] in include] \n",
    "y_cols = ['offer_end_change', 'sale_low_change', 'sale_high_change']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot pictures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_sim(comp, ysim, ndays, *args):\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize = (12,6))\n",
    "    x = pd.to_datetime(ysim.index, format = '%d.%m.%Y')[:ndays]\n",
    "    yl = ysim['sales_low_000'].values[:ndays]\n",
    "    yh = ysim['sales_high_000'].values[:ndays]\n",
    "    #y = ysim['offer_end_prev'].values[:ndays]\n",
    "    \n",
    "    #plt.plot_date(x,y, linestyle = '-', marker = None)\n",
    "    plt.fill_between(x,yl,yh, linestyle = '-')\n",
    "    plt.ylabel('Sales lowest to highest filled')\n",
    "    #[plt.gca().axvline(xi, alpha = .1) for xi in x]\n",
    "    \n",
    "    if len(args) == 3:\n",
    "        pred, truth, col = [arg[:ndays] for arg in args]\n",
    "        \n",
    "        correct = pred & truth\n",
    "        fp = pred & np.logical_not(truth)\n",
    "        \n",
    "        plt.scatter(x[correct], yh[correct], s = 40, alpha = .7, \n",
    "                    c = 'green', label = col + ' correct')\n",
    "        plt.scatter(x[truth], yh[truth], s = 20, c = 'red', alpha = .2,\n",
    "                    label = col + ' true')\n",
    "        \n",
    "    else:    \n",
    "        plt.twinx()\n",
    "        y2 = ysim['offer_end_change']*100\n",
    "        plt.plot_date(x,y2, linestyle = '-', marker = None, color = 'red')\n",
    "        plt.ylabel('Offer end percentage change')\n",
    "    \n",
    "    plt.legend(frameon = False)\n",
    "    plt.title(comp, fontsize = 14)\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make estimator pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-ce9b86496850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;31m#('pca', PCA()),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0;34m'sel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     ('rf', RandomForestClassifier())]) \n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m params_rf = [{'sel__k': np.arange(40,100,10),\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "pipe_rf = Pipeline([('pol', PolynomialFeatures(degree = 2, interaction_only = True)),\n",
    "                    ('var', VarianceThreshold()),\n",
    "                    ('sel', SelectKBest())\n",
    "                    ('rf', RandomForestClassifier())]) \n",
    "\n",
    "params_rf = [{'sel__k': np.arange(40,100,10),\n",
    "              'rf__max_features': np.arange(5,30,5),\n",
    "              'rf__max_depth': [5,10,20],\n",
    "              'rf__n_estimators': [20,50,100]}]\n",
    "\n",
    "pipe_gbm = Pipeline([('pol', PolynomialFeatures(degree = 2, interaction_only = True)),\n",
    "                     ('var', VarianceThreshold()),\n",
    "                     #('scale', StandardScaler()),\n",
    "                     #('pca', PCA()),\n",
    "                     ('gbm', GradientBoostingClassifier())]) \n",
    "\n",
    "params_gbm = [{'pca__n_components': np.arange(40,100,10),\n",
    "                'rf__max_features': np.arange(5,30,5),\n",
    "                'rf__max_depth': [5,10,20],\n",
    "                'rf__n_estimators': [20,50,100]}]\n",
    "\n",
    "\n",
    "def get_pipe(key):\n",
    "    if key == 'rf':\n",
    "        return pipe_rf, params_rf\n",
    "    elif key == 'gbm':\n",
    "        return pipe_gbm, params_gbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make custom fit for each company:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_estimator(comp, y, threshold, pipe, params, ntest = 50, metric = 'roc_auc'):\n",
    "    \n",
    "    splitter = StratifiedKFold(n_splits = 5, shuffle = True) #, random_state = 0)\n",
    "    X,_,ysim = comp_dict[comp]\n",
    "    X = X[cols_keep]\n",
    "    \n",
    "    y_bin = threshold < y\n",
    "    \n",
    "    X_test, y_test = X[:ntest], y_bin[:ntest]\n",
    "    X_train, y_train = X[ntest:], y_bin[ntest:]\n",
    "    Xy = [X_train, X_test, y_train, y_test, ysim, y_bin]\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(pipe, params, scoring = metric, n_jobs = 5, \n",
    "                        cv = splitter, verbose = 1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return Xy, grid.best_estimator_, grid.best_params_, grid.best_score_\n",
    "\n",
    "\n",
    "def get_scores(y_pred_train, y_pred_test, y_pred_train_p, \n",
    "               y_pred_test_p, y_train, y_test, show_report = False):\n",
    "    try:\n",
    "        roc_auc_test = roc_auc_score(y_test, y_pred_test_p)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        roc_auc_test = -1\n",
    "    \n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    \n",
    "    if show_report:\n",
    "        print('Train set classification')\n",
    "        print(classification_report(y_train, y_pred_train, target_names = ['not rise', 'rise']))\n",
    "        print(confusion_matrix(y_train, y_pred_train))\n",
    "        print('Train roc_auc = {:.3f}'.format(roc_auc_score(y_train, y_pred_train_p)))\n",
    "        print('\\nTest set classification')\n",
    "        print(classification_report(y_test, y_pred_test, target_names = ['not rise', 'rise']))\n",
    "        print(confusion_matrix(y_test, y_pred_test))\n",
    "        print('Test roc_auc = {:.3f}\\n'.format(roc_auc_test))\n",
    "    \n",
    "    return roc_auc_test, precision_test\n",
    "\n",
    "def get_prediction(Xy, estimator, show_report = False):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Xy[:4]\n",
    "    y_pred_train = estimator.predict(X_train)\n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "    y_pred_train_p = estimator.predict_proba(X_train)[:,1]\n",
    "    y_pred_test_p = estimator.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    \n",
    "    return y_pred_train, y_pred_test, y_pred_train_p, y_pred_test_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed the pipe to fit for each company and collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktia Pankki A   offer_end_change\n",
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f73c6c829c0, file \"/...3.5/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/dist-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f73c6c829c0, file \"/...3.5/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/dist-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 4, 16, 55, 6, 588393, tzinfo=tzutc()), 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'session': '2B4D6E377E97435C8BEBB6731E86503B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2B4D6E377E97435C8BEBB6731E86503B']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 4, 16, 55, 6, 588393, tzinfo=tzutc()), 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'session': '2B4D6E377E97435C8BEBB6731E86503B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2B4D6E377E97435C8BEBB6731E86503B'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 4, 16, 55, 6, 588393, tzinfo=tzutc()), 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'session': '2B4D6E377E97435C8BEBB6731E86503B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.FunctionDef object>, <_ast.Assign object>], cell_name='<ipython-input-48-0c6de7a59909>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f7384284e10, executi..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7382ce8f60, file \"<ipython-input-48-0c6de7a59909>\", line 62>\n        result = <ExecutionResult object at 7f7384284e10, executi..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7382ce8f60, file \"<ipython-input-48-0c6de7a59909>\", line 62>, result=<ExecutionResult object at 7f7384284e10, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7382ce8f60, file \"<ipython-input-48-0c6de7a59909>\", line 62>\n        self.user_global_ns = {'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...el_selection import GridSearchCV, StratifiedKFold', 'df, companies = get_companies_list(2)\\n# learner ...t[comp] = get_X_y(df, comp, nfut, nhist, totHist)', \"X_orig, y, ysim = comp_dict[comp]\\nprint(X_orig.c...d_change', 'sale_low_change', 'sale_high_change']\", 'def plot_sim(comp, ysim, ndays, *args):\\n    \\n   ...plt.title(comp, fontsize = 14)\\n    plt.show()\\n   ', \"pipe_rf = Pipeline([('pol', PolynomialFeatures(d...key == 'gbm':\\n        return pipe_gbm, params_gbm\", 'def comp_estimator(comp, y, threshold, pipe, par...train, y_pred_test, y_pred_train_p, y_pred_test_p', \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...rn pred_df\\n\\nget_prediction_df()['Aktia Pankki A']\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...rn pred_df\\n\\nget_prediction_df()['Aktia Pankki A']\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", ...], 'Out': {7:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 9:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 12:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 13:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 14:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 15:     Aktia Pankki A                              ...0  \n9              0.0  \n\n[10 rows x 244 columns], 22:     Aktia Pankki A                              ...0  \n9              0.0  \n\n[10 rows x 244 columns], 26:              Aktia Pankki A                     ...   NaN            NaN  \n\n[100 rows x 366 columns], 27:              Aktia Pankki A                     ...   NaN            NaN  \n\n[100 rows x 366 columns], 28:             offer_end_change  sale_low_change+1 ...    NaN             NaN  \n\n[100 rows x 6 columns], ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PolynomialFeatures': <class 'sklearn.preprocessing.data.PolynomialFeatures'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SelectKBest': <class 'sklearn.feature_selection.univariate_selection.SelectKBest'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n        self.user_ns = {'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...el_selection import GridSearchCV, StratifiedKFold', 'df, companies = get_companies_list(2)\\n# learner ...t[comp] = get_X_y(df, comp, nfut, nhist, totHist)', \"X_orig, y, ysim = comp_dict[comp]\\nprint(X_orig.c...d_change', 'sale_low_change', 'sale_high_change']\", 'def plot_sim(comp, ysim, ndays, *args):\\n    \\n   ...plt.title(comp, fontsize = 14)\\n    plt.show()\\n   ', \"pipe_rf = Pipeline([('pol', PolynomialFeatures(d...key == 'gbm':\\n        return pipe_gbm, params_gbm\", 'def comp_estimator(comp, y, threshold, pipe, par...train, y_pred_test, y_pred_train_p, y_pred_test_p', \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...rn pred_df\\n\\nget_prediction_df()['Aktia Pankki A']\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...rn pred_df\\n\\nget_prediction_df()['Aktia Pankki A']\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", ...], 'Out': {7:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 9:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 12:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 13:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 14:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 15:     Aktia Pankki A                              ...0  \n9              0.0  \n\n[10 rows x 244 columns], 22:     Aktia Pankki A                              ...0  \n9              0.0  \n\n[10 rows x 244 columns], 26:              Aktia Pankki A                     ...   NaN            NaN  \n\n[100 rows x 366 columns], 27:              Aktia Pankki A                     ...   NaN            NaN  \n\n[100 rows x 366 columns], 28:             offer_end_change  sale_low_change+1 ...    NaN             NaN  \n\n[100 rows x 6 columns], ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PolynomialFeatures': <class 'sklearn.preprocessing.data.PolynomialFeatures'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SelectKBest': <class 'sklearn.feature_selection.univariate_selection.SelectKBest'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/home/topiko/Workspace/FinStk2/<ipython-input-48-0c6de7a59909> in <module>()\n     57                  \n     58                 print(results_dict[comp])\n     59                 np.save('opm_params_{}'.format(key), results_dict)\n     60     return results_dict\n     61 \n---> 62 results_dict = fit_and_report(companies, 'rf', ntest = 50, show = True)\n     63     \n\n...........................................................................\n/home/topiko/Workspace/FinStk2/<ipython-input-48-0c6de7a59909> in fit_and_report(companies=['Aktia Pankki A', 'Alma Media', 'Amer Sports A', 'Aspo', 'Atria A', 'Basware', 'Bittium', 'CapMan', 'Cargotec', 'Citycon', 'Cramo', 'Elisa', 'F-Secure', 'Finnair', 'Fiskars', 'Fortum', 'Glaston', 'HKScan A', 'HuhtamÃ¤ki', 'Kemira', ...], key='rf', ntest=50, show=True)\n     25                 X = X[cols_keep]\n     26 \n     27                 Xy, estimator_r, params_opm_r, score_r                     = comp_estimator(comp, y[col].values,\n     28                                      thres[col], pipe, params,\n     29                                      ntest = ntest,\n---> 30                                      metric = 'roc_auc')\n     31 \n     32                 y_pred_train, y_pred_test, y_pred_train_p, y_pred_test_p                     = get_prediction(Xy, estimator_r)\n     33 \n     34                 roc_auc, precision = get_scores(y_pred_train, \n\n...........................................................................\n/home/topiko/Workspace/FinStk2/<ipython-input-41-3feac741d67b> in comp_estimator(comp='Aktia Pankki A', y=array([ 0.00106952, -0.00106724,  0.00107066, ...,  0.01620029,\n       -0.02305476,  0.00147493]), threshold=0.01, pipe=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), params=[{'pca__n_components': array([40, 50, 60, 70, 80, 90]), 'rf__max_depth': [5, 10, 20], 'rf__max_features': array([ 5, 10, 15, 20, 25]), 'rf__n_estimators': [20, 50, 100]}], ntest=50, metric='roc_auc')\n     11     Xy = [X_train, X_test, y_train, y_test, ysim, y_bin]\n     12     \n     13     \n     14     grid = GridSearchCV(pipe, params, scoring = metric, n_jobs = 5, \n     15                         cv = splitter, verbose = 1)\n---> 16     grid.fit(X_train, y_train)\n     17     \n     18     return Xy, grid.best_estimator_, grid.best_params_, grid.best_score_\n     19 \n     20 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=5, rand..._score=True,\n       scoring='roc_auc', verbose=1), X=            change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], y=array([ True,  True, False, ...,  True, False, False], dtype=bool), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of StratifiedKFold(n_splits=5, random_state=None, shuffle=True)>\n        X =             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns]\n        y = array([ True,  True, False, ...,  True, False, False], dtype=bool)\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=5), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=5)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Nov  4 17:55:06 2017\nPID: 8761                                    Python 3.5.2: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]),             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], array([ True,  True, False, ...,  True, False, False], dtype=bool), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), 1, {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]),             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], array([ True,  True, False, ...,  True, False, False], dtype=bool), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), 1, {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), X=            change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], y=array([ True,  True, False, ...,  True, False, False], dtype=bool), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), test=array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), verbose=1, parameters={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...one, verbose=0,\n            warm_start=False))])>\n        parameters = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), **kwargs={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...one, verbose=0,\n            warm_start=False))])>\n        kwargs = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), attr='steps', **params={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...one, verbose=0,\n            warm_start=False))])>\n        params = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), **params={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n    269                 name, sub_name = split\n    270                 if name not in valid_params:\n    271                     raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                      'Check the list of available parameters '\n    273                                      'with `estimator.get_params().keys()`.' %\n--> 274                                      (name, self))\n        name = 'pca'\n        self = Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))])\n    275                 sub_object = valid_params[name]\n    276                 sub_object.set_params(**{sub_name: value})\n    277             else:\n    278                 # simple objects case\n\nValueError: Invalid parameter pca for estimator Pipeline(memory=None,\n     steps=[('pol', PolynomialFeatures(degree=2, include_bias=True, interaction_only=True)), ('var', VarianceThreshold(threshold=0.0)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=5, max_features=5, max_leaf_nodes=None,\n            min_impurity...n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"<ipython-input-48-0c6de7a59909>\", line 18, in fit_and_report\n    results_dict[comp][col]\nKeyError: 'Aktia Pankki A'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\", line 423, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\", line 144, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/base.py\", line 274, in set_params\n    (name, self))\nValueError: Invalid parameter pca for estimator Pipeline(memory=None,\n     steps=[('pol', PolynomialFeatures(degree=2, include_bias=True, interaction_only=True)), ('var', VarianceThreshold(threshold=0.0)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=5, max_features=5, max_leaf_nodes=None,\n            min_impurity...n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Nov  4 17:55:06 2017\nPID: 8761                                    Python 3.5.2: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]),             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], array([ True,  True, False, ...,  True, False, False], dtype=bool), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), 1, {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]),             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], array([ True,  True, False, ...,  True, False, False], dtype=bool), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), 1, {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), X=            change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], y=array([ True,  True, False, ...,  True, False, False], dtype=bool), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), test=array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), verbose=1, parameters={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...one, verbose=0,\n            warm_start=False))])>\n        parameters = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), **kwargs={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...one, verbose=0,\n            warm_start=False))])>\n        kwargs = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), attr='steps', **params={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...one, verbose=0,\n            warm_start=False))])>\n        params = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), **params={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n    269                 name, sub_name = split\n    270                 if name not in valid_params:\n    271                     raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                      'Check the list of available parameters '\n    273                                      'with `estimator.get_params().keys()`.' %\n--> 274                                      (name, self))\n        name = 'pca'\n        self = Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))])\n    275                 sub_object = valid_params[name]\n    276                 sub_object.set_params(**{sub_name: value})\n    277             else:\n    278                 # simple objects case\n\nValueError: Invalid parameter pca for estimator Pipeline(memory=None,\n     steps=[('pol', PolynomialFeatures(degree=2, include_bias=True, interaction_only=True)), ('var', VarianceThreshold(threshold=0.0)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=5, max_features=5, max_leaf_nodes=None,\n            min_impurity...n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Nov  4 17:55:06 2017\nPID: 8761                                    Python 3.5.2: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]),             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], array([ True,  True, False, ...,  True, False, False], dtype=bool), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), 1, {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]),             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], array([ True,  True, False, ...,  True, False, False], dtype=bool), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), 1, {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), X=            change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], y=array([ True,  True, False, ...,  True, False, False], dtype=bool), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), test=array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), verbose=1, parameters={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...one, verbose=0,\n            warm_start=False))])>\n        parameters = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), **kwargs={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...one, verbose=0,\n            warm_start=False))])>\n        kwargs = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), attr='steps', **params={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...one, verbose=0,\n            warm_start=False))])>\n        params = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), **params={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n    269                 name, sub_name = split\n    270                 if name not in valid_params:\n    271                     raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                      'Check the list of available parameters '\n    273                                      'with `estimator.get_params().keys()`.' %\n--> 274                                      (name, self))\n        name = 'pca'\n        self = Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))])\n    275                 sub_object = valid_params[name]\n    276                 sub_object.set_params(**{sub_name: value})\n    277             else:\n    278                 # simple objects case\n\nValueError: Invalid parameter pca for estimator Pipeline(memory=None,\n     steps=[('pol', PolynomialFeatures(degree=2, include_bias=True, interaction_only=True)), ('var', VarianceThreshold(threshold=0.0)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=5, max_features=5, max_leaf_nodes=None,\n            min_impurity...n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-0c6de7a59909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mresults_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_and_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompanies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-0c6de7a59909>\u001b[0m in \u001b[0;36mfit_and_report\u001b[0;34m(companies, key, ntest, show)\u001b[0m\n\u001b[1;32m     28\u001b[0m                                      \u001b[0mthres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                      \u001b[0mntest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                      metric = 'roc_auc')\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test_p\u001b[0m                     \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-3feac741d67b>\u001b[0m in \u001b[0;36mcomp_estimator\u001b[0;34m(comp, y, threshold, pipe, params, ntest, metric)\u001b[0m\n\u001b[1;32m     14\u001b[0m     grid = GridSearchCV(pipe, params, scoring = metric, n_jobs = 5, \n\u001b[1;32m     15\u001b[0m                         cv = splitter, verbose = 1)\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f73c6c829c0, file \"/...3.5/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/dist-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f73c6c829c0, file \"/...3.5/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/dist-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 4, 16, 55, 6, 588393, tzinfo=tzutc()), 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'session': '2B4D6E377E97435C8BEBB6731E86503B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2B4D6E377E97435C8BEBB6731E86503B']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 4, 16, 55, 6, 588393, tzinfo=tzutc()), 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'session': '2B4D6E377E97435C8BEBB6731E86503B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2B4D6E377E97435C8BEBB6731E86503B'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 4, 16, 55, 6, 588393, tzinfo=tzutc()), 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'session': '2B4D6E377E97435C8BEBB6731E86503B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '26DC9D1BEC1F4A44982D62D5A3B8A4E5', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"def fit_and_report(companies, key = 'rf', ntest ...t(companies, 'rf', ntest = 50, show = True)\\n    \\n\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.FunctionDef object>, <_ast.Assign object>], cell_name='<ipython-input-48-0c6de7a59909>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f7384284e10, executi..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7382ce8f60, file \"<ipython-input-48-0c6de7a59909>\", line 62>\n        result = <ExecutionResult object at 7f7384284e10, executi..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7382ce8f60, file \"<ipython-input-48-0c6de7a59909>\", line 62>, result=<ExecutionResult object at 7f7384284e10, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7382ce8f60, file \"<ipython-input-48-0c6de7a59909>\", line 62>\n        self.user_global_ns = {'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...el_selection import GridSearchCV, StratifiedKFold', 'df, companies = get_companies_list(2)\\n# learner ...t[comp] = get_X_y(df, comp, nfut, nhist, totHist)', \"X_orig, y, ysim = comp_dict[comp]\\nprint(X_orig.c...d_change', 'sale_low_change', 'sale_high_change']\", 'def plot_sim(comp, ysim, ndays, *args):\\n    \\n   ...plt.title(comp, fontsize = 14)\\n    plt.show()\\n   ', \"pipe_rf = Pipeline([('pol', PolynomialFeatures(d...key == 'gbm':\\n        return pipe_gbm, params_gbm\", 'def comp_estimator(comp, y, threshold, pipe, par...train, y_pred_test, y_pred_train_p, y_pred_test_p', \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...rn pred_df\\n\\nget_prediction_df()['Aktia Pankki A']\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...rn pred_df\\n\\nget_prediction_df()['Aktia Pankki A']\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", ...], 'Out': {7:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 9:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 12:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 13:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 14:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 15:     Aktia Pankki A                              ...0  \n9              0.0  \n\n[10 rows x 244 columns], 22:     Aktia Pankki A                              ...0  \n9              0.0  \n\n[10 rows x 244 columns], 26:              Aktia Pankki A                     ...   NaN            NaN  \n\n[100 rows x 366 columns], 27:              Aktia Pankki A                     ...   NaN            NaN  \n\n[100 rows x 366 columns], 28:             offer_end_change  sale_low_change+1 ...    NaN             NaN  \n\n[100 rows x 6 columns], ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PolynomialFeatures': <class 'sklearn.preprocessing.data.PolynomialFeatures'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SelectKBest': <class 'sklearn.feature_selection.univariate_selection.SelectKBest'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n        self.user_ns = {'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...el_selection import GridSearchCV, StratifiedKFold', 'df, companies = get_companies_list(2)\\n# learner ...t[comp] = get_X_y(df, comp, nfut, nhist, totHist)', \"X_orig, y, ysim = comp_dict[comp]\\nprint(X_orig.c...d_change', 'sale_low_change', 'sale_high_change']\", 'def plot_sim(comp, ysim, ndays, *args):\\n    \\n   ...plt.title(comp, fontsize = 14)\\n    plt.show()\\n   ', \"pipe_rf = Pipeline([('pol', PolynomialFeatures(d...key == 'gbm':\\n        return pipe_gbm, params_gbm\", 'def comp_estimator(comp, y, threshold, pipe, par...train, y_pred_test, y_pred_train_p, y_pred_test_p', \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...rn pred_df\\n\\nget_prediction_df()['Aktia Pankki A']\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...rn pred_df\\n\\nget_prediction_df()['Aktia Pankki A']\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...col)\\n    \\n    return pred_df\\n\\nget_prediction_df()\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", \"# optimal parameters:\\nkey = 'rf'\\n#opm_params = n...)\\n    \\n    return pred_df\\n\\nget_prediction_df(100)\", ...], 'Out': {7:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 9:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 12:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 13:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 14:    (Aktia Pankki A, offer_end_change)  (Aktia Pa...                   0.0  \n\n[10 rows x 244 columns], 15:     Aktia Pankki A                              ...0  \n9              0.0  \n\n[10 rows x 244 columns], 22:     Aktia Pankki A                              ...0  \n9              0.0  \n\n[10 rows x 244 columns], 26:              Aktia Pankki A                     ...   NaN            NaN  \n\n[100 rows x 366 columns], 27:              Aktia Pankki A                     ...   NaN            NaN  \n\n[100 rows x 366 columns], 28:             offer_end_change  sale_low_change+1 ...    NaN             NaN  \n\n[100 rows x 6 columns], ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PolynomialFeatures': <class 'sklearn.preprocessing.data.PolynomialFeatures'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SelectKBest': <class 'sklearn.feature_selection.univariate_selection.SelectKBest'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/home/topiko/Workspace/FinStk2/<ipython-input-48-0c6de7a59909> in <module>()\n     57                  \n     58                 print(results_dict[comp])\n     59                 np.save('opm_params_{}'.format(key), results_dict)\n     60     return results_dict\n     61 \n---> 62 results_dict = fit_and_report(companies, 'rf', ntest = 50, show = True)\n     63     \n\n...........................................................................\n/home/topiko/Workspace/FinStk2/<ipython-input-48-0c6de7a59909> in fit_and_report(companies=['Aktia Pankki A', 'Alma Media', 'Amer Sports A', 'Aspo', 'Atria A', 'Basware', 'Bittium', 'CapMan', 'Cargotec', 'Citycon', 'Cramo', 'Elisa', 'F-Secure', 'Finnair', 'Fiskars', 'Fortum', 'Glaston', 'HKScan A', 'HuhtamÃ¤ki', 'Kemira', ...], key='rf', ntest=50, show=True)\n     25                 X = X[cols_keep]\n     26 \n     27                 Xy, estimator_r, params_opm_r, score_r                     = comp_estimator(comp, y[col].values,\n     28                                      thres[col], pipe, params,\n     29                                      ntest = ntest,\n---> 30                                      metric = 'roc_auc')\n     31 \n     32                 y_pred_train, y_pred_test, y_pred_train_p, y_pred_test_p                     = get_prediction(Xy, estimator_r)\n     33 \n     34                 roc_auc, precision = get_scores(y_pred_train, \n\n...........................................................................\n/home/topiko/Workspace/FinStk2/<ipython-input-41-3feac741d67b> in comp_estimator(comp='Aktia Pankki A', y=array([ 0.00106952, -0.00106724,  0.00107066, ...,  0.01620029,\n       -0.02305476,  0.00147493]), threshold=0.01, pipe=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), params=[{'pca__n_components': array([40, 50, 60, 70, 80, 90]), 'rf__max_depth': [5, 10, 20], 'rf__max_features': array([ 5, 10, 15, 20, 25]), 'rf__n_estimators': [20, 50, 100]}], ntest=50, metric='roc_auc')\n     11     Xy = [X_train, X_test, y_train, y_test, ysim, y_bin]\n     12     \n     13     \n     14     grid = GridSearchCV(pipe, params, scoring = metric, n_jobs = 5, \n     15                         cv = splitter, verbose = 1)\n---> 16     grid.fit(X_train, y_train)\n     17     \n     18     return Xy, grid.best_estimator_, grid.best_params_, grid.best_score_\n     19 \n     20 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=5, rand..._score=True,\n       scoring='roc_auc', verbose=1), X=            change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], y=array([ True,  True, False, ...,  True, False, False], dtype=bool), groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of StratifiedKFold(n_splits=5, random_state=None, shuffle=True)>\n        X =             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns]\n        y = array([ True,  True, False, ...,  True, False, False], dtype=bool)\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=5), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=5)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Nov  4 17:55:06 2017\nPID: 8761                                    Python 3.5.2: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]),             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], array([ True,  True, False, ...,  True, False, False], dtype=bool), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), 1, {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]),             change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], array([ True,  True, False, ...,  True, False, False], dtype=bool), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), 1, {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), X=            change_Me_-01  change_Me_-02  change...06.2013     -0.011364  \n\n[1045 rows x 40 columns], y=array([ True,  True, False, ...,  True, False, False], dtype=bool), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([   0,    1,    2,    3,    4,    5,    6,... 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044]), test=array([   7,   10,   17,   18,   21,   25,   29,... 998, 1003, 1005, 1007, 1013, 1018,\n       1038]), verbose=1, parameters={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...one, verbose=0,\n            warm_start=False))])>\n        parameters = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), **kwargs={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...one, verbose=0,\n            warm_start=False))])>\n        kwargs = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), attr='steps', **params={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...one, verbose=0,\n            warm_start=False))])>\n        params = {'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))]), **params={'pca__n_components': 40, 'rf__max_depth': 5, 'rf__max_features': 5, 'rf__n_estimators': 20})\n    269                 name, sub_name = split\n    270                 if name not in valid_params:\n    271                     raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                      'Check the list of available parameters '\n    273                                      'with `estimator.get_params().keys()`.' %\n--> 274                                      (name, self))\n        name = 'pca'\n        self = Pipeline(memory=None,\n     steps=[('pol', Polyno...None, verbose=0,\n            warm_start=False))])\n    275                 sub_object = valid_params[name]\n    276                 sub_object.set_params(**{sub_name: value})\n    277             else:\n    278                 # simple objects case\n\nValueError: Invalid parameter pca for estimator Pipeline(memory=None,\n     steps=[('pol', PolynomialFeatures(degree=2, include_bias=True, interaction_only=True)), ('var', VarianceThreshold(threshold=0.0)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=5, max_features=5, max_leaf_nodes=None,\n            min_impurity...n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "def fit_and_report(companies, key = 'rf', ntest = 100, show = False):\n",
    "    \n",
    "    thres = {'offer_end_change':.01, \n",
    "             'sale_low_change+1':.0,\n",
    "             'sale_low_change':.01,\n",
    "             'sale_high_change':.01}\n",
    "    \n",
    "    pipe, params = get_pipe(key)\n",
    "    try:\n",
    "        results_dict = np.load('opm_params_{}.npy'.format(key)).item()        \n",
    "    except FileNotFoundError:\n",
    "        results_dict = {}\n",
    "    \n",
    "    for comp in companies:\n",
    "        y = comp_dict[comp][1]\n",
    "        for col in y.columns.values:\n",
    "            try:\n",
    "                results_dict[comp][col]\n",
    "            except KeyError:\n",
    "                \n",
    "                \n",
    "                print(comp, ' ', col)\n",
    "\n",
    "                X,_,ysim = comp_dict[comp]\n",
    "                X = X[cols_keep]\n",
    "\n",
    "                Xy, estimator_r, params_opm_r, score_r \\\n",
    "                    = comp_estimator(comp, y[col].values,\n",
    "                                     thres[col], pipe, params,\n",
    "                                     ntest = ntest,\n",
    "                                     metric = 'roc_auc')\n",
    "\n",
    "                y_pred_train, y_pred_test, y_pred_train_p, y_pred_test_p \\\n",
    "                    = get_prediction(Xy, estimator_r)\n",
    "\n",
    "                roc_auc, precision = get_scores(y_pred_train, \n",
    "                                                y_pred_test, \n",
    "                                                y_pred_train_p, \n",
    "                                                y_pred_test_p, \n",
    "                                                Xy[2], Xy[3], \n",
    "                                                show_report = show)\n",
    "\n",
    "                if show:\n",
    "                    print(params_opm_r)\n",
    "                    y_pred_tot = np.concatenate((y_pred_test, \n",
    "                                                 y_pred_train))\n",
    "                    plot_sim(comp, Xy[4], ntest*4, y_pred_tot, \n",
    "                             Xy[5], col)\n",
    "\n",
    "\n",
    "                col_dict = {col: {'roc_auc':roc_auc, \n",
    "                                  'precision':precision,\n",
    "                                  'threshold':thres[col],\n",
    "                                  'opm_params':params_opm_r}}\n",
    "                try:\n",
    "                    results_dict[comp].update(col_dict)\n",
    "                except KeyError:\n",
    "                    results_dict[comp] = col_dict\n",
    "                 \n",
    "                print(results_dict[comp])\n",
    "                np.save('opm_params_{}'.format(key), results_dict)\n",
    "    return results_dict\n",
    "\n",
    "results_dict = fit_and_report(companies, 'rf', ntest = 50, show = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then test the obtained results:\n",
    "### First make the prediction dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Aktia Pankki A</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Alma Media</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Amer Sports A</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">UPM-Kymmene</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Uponor</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Vaisala A</th>\n",
       "      <th colspan=\"2\" halign=\"left\">WÃ¤rtsilÃ¤</th>\n",
       "      <th colspan=\"2\" halign=\"left\">YIT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>offer_end_change</th>\n",
       "      <th>sale_low_change+1</th>\n",
       "      <th>sale_low_change</th>\n",
       "      <th>sale_high_change</th>\n",
       "      <th>offer_end_change</th>\n",
       "      <th>sale_low_change+1</th>\n",
       "      <th>sale_low_change</th>\n",
       "      <th>sale_high_change</th>\n",
       "      <th>offer_end_change</th>\n",
       "      <th>sale_low_change+1</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_low_000</th>\n",
       "      <th>sales_high_001</th>\n",
       "      <th>sales_low_000</th>\n",
       "      <th>sales_high_001</th>\n",
       "      <th>sales_low_000</th>\n",
       "      <th>sales_high_001</th>\n",
       "      <th>sales_low_000</th>\n",
       "      <th>sales_high_001</th>\n",
       "      <th>sales_low_000</th>\n",
       "      <th>sales_high_001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.82</td>\n",
       "      <td>23.82</td>\n",
       "      <td>14.83</td>\n",
       "      <td>15.05</td>\n",
       "      <td>43.23</td>\n",
       "      <td>44.70</td>\n",
       "      <td>60.35</td>\n",
       "      <td>62.30</td>\n",
       "      <td>7.04</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.91</td>\n",
       "      <td>24.03</td>\n",
       "      <td>14.81</td>\n",
       "      <td>14.99</td>\n",
       "      <td>43.85</td>\n",
       "      <td>44.40</td>\n",
       "      <td>59.30</td>\n",
       "      <td>62.00</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.83</td>\n",
       "      <td>24.22</td>\n",
       "      <td>14.76</td>\n",
       "      <td>14.95</td>\n",
       "      <td>43.95</td>\n",
       "      <td>44.00</td>\n",
       "      <td>58.75</td>\n",
       "      <td>60.75</td>\n",
       "      <td>7.04</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.70</td>\n",
       "      <td>24.23</td>\n",
       "      <td>14.76</td>\n",
       "      <td>14.94</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.19</td>\n",
       "      <td>58.95</td>\n",
       "      <td>59.40</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.72</td>\n",
       "      <td>23.87</td>\n",
       "      <td>14.74</td>\n",
       "      <td>14.92</td>\n",
       "      <td>43.34</td>\n",
       "      <td>44.42</td>\n",
       "      <td>59.00</td>\n",
       "      <td>59.60</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.54</td>\n",
       "      <td>23.98</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.88</td>\n",
       "      <td>44.17</td>\n",
       "      <td>45.00</td>\n",
       "      <td>58.85</td>\n",
       "      <td>59.50</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.63</td>\n",
       "      <td>23.93</td>\n",
       "      <td>14.66</td>\n",
       "      <td>14.79</td>\n",
       "      <td>44.43</td>\n",
       "      <td>45.00</td>\n",
       "      <td>58.60</td>\n",
       "      <td>59.65</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>24.07</td>\n",
       "      <td>14.52</td>\n",
       "      <td>14.78</td>\n",
       "      <td>43.91</td>\n",
       "      <td>45.45</td>\n",
       "      <td>60.45</td>\n",
       "      <td>59.75</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.40</td>\n",
       "      <td>23.95</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.76</td>\n",
       "      <td>43.80</td>\n",
       "      <td>45.00</td>\n",
       "      <td>60.60</td>\n",
       "      <td>61.00</td>\n",
       "      <td>6.94</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.21</td>\n",
       "      <td>23.80</td>\n",
       "      <td>14.61</td>\n",
       "      <td>14.69</td>\n",
       "      <td>43.30</td>\n",
       "      <td>44.88</td>\n",
       "      <td>60.05</td>\n",
       "      <td>61.30</td>\n",
       "      <td>6.98</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02.10.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.94</td>\n",
       "      <td>23.62</td>\n",
       "      <td>14.57</td>\n",
       "      <td>14.74</td>\n",
       "      <td>43.47</td>\n",
       "      <td>44.00</td>\n",
       "      <td>59.70</td>\n",
       "      <td>60.95</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.91</td>\n",
       "      <td>23.18</td>\n",
       "      <td>14.50</td>\n",
       "      <td>14.70</td>\n",
       "      <td>43.00</td>\n",
       "      <td>43.70</td>\n",
       "      <td>59.10</td>\n",
       "      <td>60.25</td>\n",
       "      <td>6.88</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.69</td>\n",
       "      <td>23.15</td>\n",
       "      <td>14.41</td>\n",
       "      <td>14.71</td>\n",
       "      <td>42.60</td>\n",
       "      <td>44.00</td>\n",
       "      <td>59.45</td>\n",
       "      <td>59.95</td>\n",
       "      <td>6.91</td>\n",
       "      <td>6.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.58</td>\n",
       "      <td>23.10</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.71</td>\n",
       "      <td>42.61</td>\n",
       "      <td>43.50</td>\n",
       "      <td>58.85</td>\n",
       "      <td>59.90</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.58</td>\n",
       "      <td>22.80</td>\n",
       "      <td>14.16</td>\n",
       "      <td>14.47</td>\n",
       "      <td>42.54</td>\n",
       "      <td>43.30</td>\n",
       "      <td>58.45</td>\n",
       "      <td>59.80</td>\n",
       "      <td>6.89</td>\n",
       "      <td>6.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.61</td>\n",
       "      <td>22.89</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.40</td>\n",
       "      <td>43.70</td>\n",
       "      <td>43.70</td>\n",
       "      <td>58.60</td>\n",
       "      <td>59.40</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.59</td>\n",
       "      <td>22.90</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.40</td>\n",
       "      <td>42.25</td>\n",
       "      <td>44.00</td>\n",
       "      <td>58.90</td>\n",
       "      <td>59.75</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.48</td>\n",
       "      <td>22.92</td>\n",
       "      <td>14.34</td>\n",
       "      <td>14.46</td>\n",
       "      <td>42.10</td>\n",
       "      <td>43.99</td>\n",
       "      <td>59.30</td>\n",
       "      <td>59.75</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.42</td>\n",
       "      <td>22.90</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.50</td>\n",
       "      <td>42.12</td>\n",
       "      <td>42.38</td>\n",
       "      <td>59.30</td>\n",
       "      <td>59.85</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.48</td>\n",
       "      <td>22.63</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.45</td>\n",
       "      <td>41.99</td>\n",
       "      <td>43.00</td>\n",
       "      <td>58.85</td>\n",
       "      <td>59.80</td>\n",
       "      <td>6.96</td>\n",
       "      <td>7.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.80</td>\n",
       "      <td>14.20</td>\n",
       "      <td>14.52</td>\n",
       "      <td>41.92</td>\n",
       "      <td>42.50</td>\n",
       "      <td>57.85</td>\n",
       "      <td>59.95</td>\n",
       "      <td>6.94</td>\n",
       "      <td>7.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.19</td>\n",
       "      <td>22.80</td>\n",
       "      <td>14.17</td>\n",
       "      <td>14.43</td>\n",
       "      <td>41.40</td>\n",
       "      <td>42.97</td>\n",
       "      <td>57.55</td>\n",
       "      <td>59.00</td>\n",
       "      <td>6.94</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.23</td>\n",
       "      <td>22.37</td>\n",
       "      <td>14.31</td>\n",
       "      <td>14.42</td>\n",
       "      <td>41.30</td>\n",
       "      <td>42.49</td>\n",
       "      <td>57.65</td>\n",
       "      <td>58.15</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.64</td>\n",
       "      <td>22.66</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.49</td>\n",
       "      <td>41.50</td>\n",
       "      <td>42.22</td>\n",
       "      <td>57.30</td>\n",
       "      <td>58.10</td>\n",
       "      <td>7.04</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.74</td>\n",
       "      <td>23.00</td>\n",
       "      <td>14.11</td>\n",
       "      <td>14.49</td>\n",
       "      <td>41.29</td>\n",
       "      <td>42.28</td>\n",
       "      <td>58.25</td>\n",
       "      <td>58.25</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.27</td>\n",
       "      <td>23.15</td>\n",
       "      <td>13.65</td>\n",
       "      <td>14.57</td>\n",
       "      <td>41.40</td>\n",
       "      <td>42.28</td>\n",
       "      <td>58.35</td>\n",
       "      <td>59.20</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.02</td>\n",
       "      <td>22.65</td>\n",
       "      <td>13.46</td>\n",
       "      <td>13.97</td>\n",
       "      <td>40.58</td>\n",
       "      <td>42.79</td>\n",
       "      <td>57.40</td>\n",
       "      <td>59.10</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.92</td>\n",
       "      <td>22.30</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.61</td>\n",
       "      <td>39.43</td>\n",
       "      <td>41.65</td>\n",
       "      <td>56.40</td>\n",
       "      <td>58.20</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.61</td>\n",
       "      <td>22.20</td>\n",
       "      <td>13.39</td>\n",
       "      <td>13.54</td>\n",
       "      <td>39.42</td>\n",
       "      <td>41.81</td>\n",
       "      <td>57.50</td>\n",
       "      <td>57.70</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.09.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.78</td>\n",
       "      <td>22.04</td>\n",
       "      <td>13.58</td>\n",
       "      <td>13.64</td>\n",
       "      <td>39.41</td>\n",
       "      <td>39.97</td>\n",
       "      <td>57.70</td>\n",
       "      <td>57.95</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.07.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.21</td>\n",
       "      <td>25.58</td>\n",
       "      <td>15.59</td>\n",
       "      <td>15.85</td>\n",
       "      <td>43.23</td>\n",
       "      <td>45.00</td>\n",
       "      <td>52.45</td>\n",
       "      <td>54.30</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07.07.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.05</td>\n",
       "      <td>25.50</td>\n",
       "      <td>15.61</td>\n",
       "      <td>15.84</td>\n",
       "      <td>43.38</td>\n",
       "      <td>43.94</td>\n",
       "      <td>52.45</td>\n",
       "      <td>54.05</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06.07.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.29</td>\n",
       "      <td>25.45</td>\n",
       "      <td>15.72</td>\n",
       "      <td>15.92</td>\n",
       "      <td>43.03</td>\n",
       "      <td>44.00</td>\n",
       "      <td>52.10</td>\n",
       "      <td>53.10</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.07.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.77</td>\n",
       "      <td>15.78</td>\n",
       "      <td>15.98</td>\n",
       "      <td>43.38</td>\n",
       "      <td>44.00</td>\n",
       "      <td>52.50</td>\n",
       "      <td>53.00</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.07.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.07</td>\n",
       "      <td>25.70</td>\n",
       "      <td>15.77</td>\n",
       "      <td>16.06</td>\n",
       "      <td>43.05</td>\n",
       "      <td>43.99</td>\n",
       "      <td>52.35</td>\n",
       "      <td>53.35</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03.07.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.01</td>\n",
       "      <td>25.38</td>\n",
       "      <td>15.93</td>\n",
       "      <td>16.05</td>\n",
       "      <td>43.10</td>\n",
       "      <td>43.66</td>\n",
       "      <td>52.00</td>\n",
       "      <td>52.80</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.64</td>\n",
       "      <td>25.41</td>\n",
       "      <td>15.72</td>\n",
       "      <td>16.08</td>\n",
       "      <td>43.54</td>\n",
       "      <td>43.66</td>\n",
       "      <td>51.50</td>\n",
       "      <td>53.10</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.67</td>\n",
       "      <td>25.05</td>\n",
       "      <td>15.81</td>\n",
       "      <td>16.10</td>\n",
       "      <td>43.00</td>\n",
       "      <td>44.26</td>\n",
       "      <td>51.75</td>\n",
       "      <td>52.05</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.80</td>\n",
       "      <td>25.60</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.32</td>\n",
       "      <td>43.65</td>\n",
       "      <td>44.61</td>\n",
       "      <td>52.45</td>\n",
       "      <td>53.25</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>25.45</td>\n",
       "      <td>15.97</td>\n",
       "      <td>16.34</td>\n",
       "      <td>44.10</td>\n",
       "      <td>44.00</td>\n",
       "      <td>53.10</td>\n",
       "      <td>53.15</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.05</td>\n",
       "      <td>25.33</td>\n",
       "      <td>16.18</td>\n",
       "      <td>16.32</td>\n",
       "      <td>44.00</td>\n",
       "      <td>44.75</td>\n",
       "      <td>54.05</td>\n",
       "      <td>54.40</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.94</td>\n",
       "      <td>25.34</td>\n",
       "      <td>16.28</td>\n",
       "      <td>16.60</td>\n",
       "      <td>43.74</td>\n",
       "      <td>45.06</td>\n",
       "      <td>53.95</td>\n",
       "      <td>54.65</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>25.61</td>\n",
       "      <td>16.22</td>\n",
       "      <td>16.67</td>\n",
       "      <td>43.78</td>\n",
       "      <td>44.89</td>\n",
       "      <td>54.45</td>\n",
       "      <td>54.60</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.89</td>\n",
       "      <td>25.92</td>\n",
       "      <td>16.40</td>\n",
       "      <td>16.48</td>\n",
       "      <td>43.65</td>\n",
       "      <td>45.40</td>\n",
       "      <td>54.90</td>\n",
       "      <td>55.00</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.87</td>\n",
       "      <td>26.46</td>\n",
       "      <td>16.56</td>\n",
       "      <td>16.66</td>\n",
       "      <td>43.53</td>\n",
       "      <td>45.00</td>\n",
       "      <td>55.35</td>\n",
       "      <td>55.85</td>\n",
       "      <td>7.66</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.40</td>\n",
       "      <td>26.45</td>\n",
       "      <td>16.17</td>\n",
       "      <td>16.75</td>\n",
       "      <td>43.20</td>\n",
       "      <td>44.75</td>\n",
       "      <td>52.50</td>\n",
       "      <td>55.85</td>\n",
       "      <td>7.46</td>\n",
       "      <td>8.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.14</td>\n",
       "      <td>25.86</td>\n",
       "      <td>16.13</td>\n",
       "      <td>16.67</td>\n",
       "      <td>43.61</td>\n",
       "      <td>46.00</td>\n",
       "      <td>52.60</td>\n",
       "      <td>55.30</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.45</td>\n",
       "      <td>25.48</td>\n",
       "      <td>16.04</td>\n",
       "      <td>16.44</td>\n",
       "      <td>45.04</td>\n",
       "      <td>46.00</td>\n",
       "      <td>53.30</td>\n",
       "      <td>53.30</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.58</td>\n",
       "      <td>25.88</td>\n",
       "      <td>15.84</td>\n",
       "      <td>16.40</td>\n",
       "      <td>44.67</td>\n",
       "      <td>46.79</td>\n",
       "      <td>52.75</td>\n",
       "      <td>53.95</td>\n",
       "      <td>7.49</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>25.85</td>\n",
       "      <td>15.75</td>\n",
       "      <td>16.20</td>\n",
       "      <td>45.20</td>\n",
       "      <td>46.71</td>\n",
       "      <td>52.35</td>\n",
       "      <td>53.50</td>\n",
       "      <td>7.46</td>\n",
       "      <td>7.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.49</td>\n",
       "      <td>25.80</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.02</td>\n",
       "      <td>46.80</td>\n",
       "      <td>46.55</td>\n",
       "      <td>52.95</td>\n",
       "      <td>53.70</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.45</td>\n",
       "      <td>25.94</td>\n",
       "      <td>15.72</td>\n",
       "      <td>16.01</td>\n",
       "      <td>47.00</td>\n",
       "      <td>47.53</td>\n",
       "      <td>52.25</td>\n",
       "      <td>53.70</td>\n",
       "      <td>7.48</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.28</td>\n",
       "      <td>25.76</td>\n",
       "      <td>15.69</td>\n",
       "      <td>16.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>47.60</td>\n",
       "      <td>53.10</td>\n",
       "      <td>53.45</td>\n",
       "      <td>7.48</td>\n",
       "      <td>7.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.64</td>\n",
       "      <td>15.76</td>\n",
       "      <td>16.05</td>\n",
       "      <td>47.01</td>\n",
       "      <td>48.15</td>\n",
       "      <td>53.00</td>\n",
       "      <td>53.50</td>\n",
       "      <td>7.54</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.28</td>\n",
       "      <td>25.53</td>\n",
       "      <td>16.02</td>\n",
       "      <td>16.15</td>\n",
       "      <td>46.80</td>\n",
       "      <td>48.00</td>\n",
       "      <td>53.15</td>\n",
       "      <td>53.60</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.31</td>\n",
       "      <td>25.53</td>\n",
       "      <td>16.10</td>\n",
       "      <td>16.32</td>\n",
       "      <td>46.57</td>\n",
       "      <td>47.90</td>\n",
       "      <td>53.95</td>\n",
       "      <td>54.25</td>\n",
       "      <td>7.60</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01.06.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.94</td>\n",
       "      <td>25.60</td>\n",
       "      <td>15.81</td>\n",
       "      <td>16.30</td>\n",
       "      <td>45.00</td>\n",
       "      <td>48.55</td>\n",
       "      <td>52.95</td>\n",
       "      <td>54.65</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.05.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>25.38</td>\n",
       "      <td>15.66</td>\n",
       "      <td>16.29</td>\n",
       "      <td>44.65</td>\n",
       "      <td>46.70</td>\n",
       "      <td>52.45</td>\n",
       "      <td>55.15</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.05.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.05</td>\n",
       "      <td>25.36</td>\n",
       "      <td>15.41</td>\n",
       "      <td>15.98</td>\n",
       "      <td>44.02</td>\n",
       "      <td>47.48</td>\n",
       "      <td>52.45</td>\n",
       "      <td>53.05</td>\n",
       "      <td>7.61</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.05.2017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.09</td>\n",
       "      <td>25.38</td>\n",
       "      <td>15.26</td>\n",
       "      <td>16.13</td>\n",
       "      <td>43.50</td>\n",
       "      <td>44.85</td>\n",
       "      <td>52.80</td>\n",
       "      <td>53.05</td>\n",
       "      <td>7.59</td>\n",
       "      <td>7.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Aktia Pankki A                                    \\\n",
       "           offer_end_change sale_low_change+1 sale_low_change   \n",
       "16.10.2017              0.0               0.0             0.0   \n",
       "13.10.2017              0.0               0.0             0.0   \n",
       "12.10.2017              0.0               0.0             0.0   \n",
       "11.10.2017              0.0               0.0             0.0   \n",
       "10.10.2017              0.0               0.0             0.0   \n",
       "09.10.2017              0.0               0.0             0.0   \n",
       "06.10.2017              0.0               0.0             0.0   \n",
       "05.10.2017              0.0               0.0             0.0   \n",
       "04.10.2017              0.0               0.0             0.0   \n",
       "03.10.2017              0.0               0.0             0.0   \n",
       "02.10.2017              0.0               0.0             0.0   \n",
       "29.09.2017              0.0               0.0             0.0   \n",
       "28.09.2017              0.0               0.0             0.0   \n",
       "27.09.2017              0.0               0.0             0.0   \n",
       "26.09.2017              0.0               0.0             0.0   \n",
       "25.09.2017              0.0               0.0             0.0   \n",
       "22.09.2017              0.0               0.0             0.0   \n",
       "21.09.2017              0.0               0.0             0.0   \n",
       "20.09.2017              0.0               0.0             0.0   \n",
       "19.09.2017              0.0               0.0             0.0   \n",
       "18.09.2017              0.0               0.0             0.0   \n",
       "15.09.2017              0.0               0.0             0.0   \n",
       "14.09.2017              0.0               0.0             0.0   \n",
       "13.09.2017              0.0               0.0             0.0   \n",
       "12.09.2017              0.0               0.0             0.0   \n",
       "11.09.2017              0.0               0.0             0.0   \n",
       "08.09.2017              0.0               0.0             0.0   \n",
       "07.09.2017              0.0               0.0             0.0   \n",
       "06.09.2017              0.0               0.0             0.0   \n",
       "05.09.2017              0.0               0.0             0.0   \n",
       "...                     ...               ...             ...   \n",
       "10.07.2017              0.0               0.0             0.0   \n",
       "07.07.2017              0.0               0.0             0.0   \n",
       "06.07.2017              0.0               0.0             0.0   \n",
       "05.07.2017              0.0               0.0             0.0   \n",
       "04.07.2017              0.0               0.0             0.0   \n",
       "03.07.2017              0.0               0.0             0.0   \n",
       "30.06.2017              0.0               0.0             0.0   \n",
       "29.06.2017              0.0               0.0             0.0   \n",
       "28.06.2017              0.0               0.0             0.0   \n",
       "27.06.2017              0.0               0.0             0.0   \n",
       "26.06.2017              0.0               0.0             0.0   \n",
       "22.06.2017              0.0               0.0             0.0   \n",
       "21.06.2017              0.0               0.0             0.0   \n",
       "20.06.2017              0.0               0.0             0.0   \n",
       "19.06.2017              0.0               0.0             0.0   \n",
       "16.06.2017              0.0               0.0             0.0   \n",
       "15.06.2017              0.0               0.0             0.0   \n",
       "14.06.2017              0.0               0.0             0.0   \n",
       "13.06.2017              0.0               0.0             0.0   \n",
       "12.06.2017              0.0               0.0             0.0   \n",
       "09.06.2017              0.0               0.0             0.0   \n",
       "08.06.2017              0.0               0.0             0.0   \n",
       "07.06.2017              0.0               0.0             0.0   \n",
       "06.06.2017              0.0               0.0             0.0   \n",
       "05.06.2017              0.0               0.0             0.0   \n",
       "02.06.2017              0.0               0.0             0.0   \n",
       "01.06.2017              0.0               0.0             0.0   \n",
       "31.05.2017              0.0               0.0             0.0   \n",
       "30.05.2017              0.0               0.0             0.0   \n",
       "29.05.2017              0.0               0.0             0.0   \n",
       "\n",
       "                                  Alma Media                    \\\n",
       "           sale_high_change offer_end_change sale_low_change+1   \n",
       "16.10.2017              0.0              0.0               0.0   \n",
       "13.10.2017              0.0              0.0               0.0   \n",
       "12.10.2017              0.0              0.0               0.0   \n",
       "11.10.2017              0.0              0.0               0.0   \n",
       "10.10.2017              0.0              0.0               0.0   \n",
       "09.10.2017              0.0              0.0               0.0   \n",
       "06.10.2017              0.0              0.0               0.0   \n",
       "05.10.2017              0.0              0.0               0.0   \n",
       "04.10.2017              0.0              0.0               0.0   \n",
       "03.10.2017              0.0              0.0               0.0   \n",
       "02.10.2017              0.0              0.0               0.0   \n",
       "29.09.2017              0.0              0.0               0.0   \n",
       "28.09.2017              0.0              0.0               0.0   \n",
       "27.09.2017              0.0              0.0               0.0   \n",
       "26.09.2017              0.0              0.0               0.0   \n",
       "25.09.2017              0.0              0.0               0.0   \n",
       "22.09.2017              0.0              0.0               0.0   \n",
       "21.09.2017              0.0              0.0               0.0   \n",
       "20.09.2017              0.0              0.0               0.0   \n",
       "19.09.2017              0.0              0.0               0.0   \n",
       "18.09.2017              0.0              0.0               0.0   \n",
       "15.09.2017              0.0              0.0               0.0   \n",
       "14.09.2017              0.0              0.0               0.0   \n",
       "13.09.2017              0.0              0.0               0.0   \n",
       "12.09.2017              0.0              0.0               0.0   \n",
       "11.09.2017              0.0              0.0               0.0   \n",
       "08.09.2017              0.0              0.0               0.0   \n",
       "07.09.2017              0.0              0.0               0.0   \n",
       "06.09.2017              0.0              0.0               0.0   \n",
       "05.09.2017              0.0              0.0               0.0   \n",
       "...                     ...              ...               ...   \n",
       "10.07.2017              0.0              0.0               0.0   \n",
       "07.07.2017              0.0              0.0               0.0   \n",
       "06.07.2017              0.0              0.0               0.0   \n",
       "05.07.2017              0.0              0.0               0.0   \n",
       "04.07.2017              0.0              0.0               0.0   \n",
       "03.07.2017              0.0              0.0               0.0   \n",
       "30.06.2017              0.0              0.0               0.0   \n",
       "29.06.2017              0.0              0.0               0.0   \n",
       "28.06.2017              0.0              0.0               0.0   \n",
       "27.06.2017              0.0              0.0               0.0   \n",
       "26.06.2017              0.0              0.0               0.0   \n",
       "22.06.2017              0.0              0.0               0.0   \n",
       "21.06.2017              0.0              0.0               0.0   \n",
       "20.06.2017              0.0              0.0               0.0   \n",
       "19.06.2017              0.0              0.0               0.0   \n",
       "16.06.2017              0.0              0.0               0.0   \n",
       "15.06.2017              0.0              0.0               0.0   \n",
       "14.06.2017              0.0              0.0               0.0   \n",
       "13.06.2017              0.0              0.0               0.0   \n",
       "12.06.2017              0.0              0.0               0.0   \n",
       "09.06.2017              0.0              0.0               0.0   \n",
       "08.06.2017              0.0              0.0               0.0   \n",
       "07.06.2017              0.0              0.0               0.0   \n",
       "06.06.2017              0.0              0.0               0.0   \n",
       "05.06.2017              0.0              0.0               0.0   \n",
       "02.06.2017              0.0              0.0               0.0   \n",
       "01.06.2017              0.0              0.0               0.0   \n",
       "31.05.2017              0.0              0.0               0.0   \n",
       "30.05.2017              0.0              0.0               0.0   \n",
       "29.05.2017              0.0              0.0               0.0   \n",
       "\n",
       "                                               Amer Sports A  \\\n",
       "           sale_low_change sale_high_change offer_end_change   \n",
       "16.10.2017             0.0              0.0              0.0   \n",
       "13.10.2017             0.0              0.0              0.0   \n",
       "12.10.2017             0.0              0.0              0.0   \n",
       "11.10.2017             0.0              0.0              0.0   \n",
       "10.10.2017             0.0              0.0              0.0   \n",
       "09.10.2017             0.0              0.0              0.0   \n",
       "06.10.2017             0.0              0.0              0.0   \n",
       "05.10.2017             0.0              0.0              0.0   \n",
       "04.10.2017             0.0              0.0              0.0   \n",
       "03.10.2017             0.0              0.0              0.0   \n",
       "02.10.2017             0.0              0.0              0.0   \n",
       "29.09.2017             0.0              0.0              0.0   \n",
       "28.09.2017             0.0              0.0              0.0   \n",
       "27.09.2017             0.0              0.0              0.0   \n",
       "26.09.2017             0.0              0.0              0.0   \n",
       "25.09.2017             0.0              0.0              0.0   \n",
       "22.09.2017             0.0              0.0              0.0   \n",
       "21.09.2017             0.0              0.0              0.0   \n",
       "20.09.2017             0.0              0.0              0.0   \n",
       "19.09.2017             0.0              0.0              0.0   \n",
       "18.09.2017             0.0              0.0              0.0   \n",
       "15.09.2017             0.0              0.0              0.0   \n",
       "14.09.2017             0.0              0.0              0.0   \n",
       "13.09.2017             0.0              0.0              0.0   \n",
       "12.09.2017             0.0              0.0              0.0   \n",
       "11.09.2017             0.0              0.0              0.0   \n",
       "08.09.2017             0.0              0.0              0.0   \n",
       "07.09.2017             0.0              0.0              0.0   \n",
       "06.09.2017             0.0              0.0              0.0   \n",
       "05.09.2017             0.0              0.0              0.0   \n",
       "...                    ...              ...              ...   \n",
       "10.07.2017             0.0              0.0              0.0   \n",
       "07.07.2017             0.0              0.0              0.0   \n",
       "06.07.2017             0.0              0.0              0.0   \n",
       "05.07.2017             0.0              0.0              0.0   \n",
       "04.07.2017             0.0              0.0              0.0   \n",
       "03.07.2017             0.0              0.0              0.0   \n",
       "30.06.2017             0.0              0.0              0.0   \n",
       "29.06.2017             0.0              0.0              0.0   \n",
       "28.06.2017             0.0              0.0              0.0   \n",
       "27.06.2017             0.0              0.0              0.0   \n",
       "26.06.2017             0.0              0.0              0.0   \n",
       "22.06.2017             0.0              0.0              0.0   \n",
       "21.06.2017             0.0              0.0              0.0   \n",
       "20.06.2017             0.0              0.0              0.0   \n",
       "19.06.2017             0.0              0.0              0.0   \n",
       "16.06.2017             0.0              0.0              0.0   \n",
       "15.06.2017             0.0              0.0              0.0   \n",
       "14.06.2017             0.0              0.0              0.0   \n",
       "13.06.2017             0.0              0.0              0.0   \n",
       "12.06.2017             0.0              0.0              0.0   \n",
       "09.06.2017             0.0              0.0              0.0   \n",
       "08.06.2017             0.0              0.0              0.0   \n",
       "07.06.2017             0.0              0.0              0.0   \n",
       "06.06.2017             0.0              0.0              0.0   \n",
       "05.06.2017             0.0              0.0              0.0   \n",
       "02.06.2017             0.0              0.0              0.0   \n",
       "01.06.2017             0.0              0.0              0.0   \n",
       "31.05.2017             0.0              0.0              0.0   \n",
       "30.05.2017             0.0              0.0              0.0   \n",
       "29.05.2017             0.0              0.0              0.0   \n",
       "\n",
       "                                  ...         UPM-Kymmene                 \\\n",
       "           sale_low_change+1      ...       sales_low_000 sales_high_001   \n",
       "16.10.2017               0.0      ...               23.82          23.82   \n",
       "13.10.2017               0.0      ...               23.91          24.03   \n",
       "12.10.2017               0.0      ...               23.83          24.22   \n",
       "11.10.2017               0.0      ...               23.70          24.23   \n",
       "10.10.2017               0.0      ...               23.72          23.87   \n",
       "09.10.2017               0.0      ...               23.54          23.98   \n",
       "06.10.2017               0.0      ...               23.63          23.93   \n",
       "05.10.2017               0.0      ...               23.69          24.07   \n",
       "04.10.2017               0.0      ...               23.40          23.95   \n",
       "03.10.2017               0.0      ...               23.21          23.80   \n",
       "02.10.2017               0.0      ...               22.94          23.62   \n",
       "29.09.2017               0.0      ...               22.91          23.18   \n",
       "28.09.2017               0.0      ...               22.69          23.15   \n",
       "27.09.2017               0.0      ...               22.58          23.10   \n",
       "26.09.2017               0.0      ...               22.58          22.80   \n",
       "25.09.2017               0.0      ...               22.61          22.89   \n",
       "22.09.2017               0.0      ...               22.59          22.90   \n",
       "21.09.2017               0.0      ...               22.48          22.92   \n",
       "20.09.2017               0.0      ...               22.42          22.90   \n",
       "19.09.2017               0.0      ...               22.48          22.63   \n",
       "18.09.2017               0.0      ...               22.40          22.80   \n",
       "15.09.2017               0.0      ...               22.19          22.80   \n",
       "14.09.2017               0.0      ...               22.23          22.37   \n",
       "13.09.2017               0.0      ...               22.64          22.66   \n",
       "12.09.2017               0.0      ...               22.74          23.00   \n",
       "11.09.2017               0.0      ...               22.27          23.15   \n",
       "08.09.2017               0.0      ...               22.02          22.65   \n",
       "07.09.2017               0.0      ...               21.92          22.30   \n",
       "06.09.2017               0.0      ...               21.61          22.20   \n",
       "05.09.2017               0.0      ...               21.78          22.04   \n",
       "...                      ...      ...                 ...            ...   \n",
       "10.07.2017               0.0      ...               25.21          25.58   \n",
       "07.07.2017               0.0      ...               25.05          25.50   \n",
       "06.07.2017               0.0      ...               25.29          25.45   \n",
       "05.07.2017               0.0      ...               25.30          25.77   \n",
       "04.07.2017               0.0      ...               25.07          25.70   \n",
       "03.07.2017               0.0      ...               25.01          25.38   \n",
       "30.06.2017               0.0      ...               24.64          25.41   \n",
       "29.06.2017               0.0      ...               24.67          25.05   \n",
       "28.06.2017               0.0      ...               24.80          25.60   \n",
       "27.06.2017               0.0      ...               24.99          25.45   \n",
       "26.06.2017               0.0      ...               25.05          25.33   \n",
       "22.06.2017               0.0      ...               24.94          25.34   \n",
       "21.06.2017               0.0      ...               25.53          25.61   \n",
       "20.06.2017               0.0      ...               25.89          25.92   \n",
       "19.06.2017               0.0      ...               25.87          26.46   \n",
       "16.06.2017               0.0      ...               25.40          26.45   \n",
       "15.06.2017               0.0      ...               25.14          25.86   \n",
       "14.06.2017               0.0      ...               25.45          25.48   \n",
       "13.06.2017               0.0      ...               25.58          25.88   \n",
       "12.06.2017               0.0      ...               25.38          25.85   \n",
       "09.06.2017               0.0      ...               25.49          25.80   \n",
       "08.06.2017               0.0      ...               25.45          25.94   \n",
       "07.06.2017               0.0      ...               25.28          25.76   \n",
       "06.06.2017               0.0      ...               25.30          25.64   \n",
       "05.06.2017               0.0      ...               25.28          25.53   \n",
       "02.06.2017               0.0      ...               25.31          25.53   \n",
       "01.06.2017               0.0      ...               24.94          25.60   \n",
       "31.05.2017               0.0      ...               24.99          25.38   \n",
       "30.05.2017               0.0      ...               25.05          25.36   \n",
       "29.05.2017               0.0      ...               25.09          25.38   \n",
       "\n",
       "                  Uponor                    Vaisala A                 \\\n",
       "           sales_low_000 sales_high_001 sales_low_000 sales_high_001   \n",
       "16.10.2017         14.83          15.05         43.23          44.70   \n",
       "13.10.2017         14.81          14.99         43.85          44.40   \n",
       "12.10.2017         14.76          14.95         43.95          44.00   \n",
       "11.10.2017         14.76          14.94         44.00          44.19   \n",
       "10.10.2017         14.74          14.92         43.34          44.42   \n",
       "09.10.2017         14.63          14.88         44.17          45.00   \n",
       "06.10.2017         14.66          14.79         44.43          45.00   \n",
       "05.10.2017         14.52          14.78         43.91          45.45   \n",
       "04.10.2017         14.51          14.76         43.80          45.00   \n",
       "03.10.2017         14.61          14.69         43.30          44.88   \n",
       "02.10.2017         14.57          14.74         43.47          44.00   \n",
       "29.09.2017         14.50          14.70         43.00          43.70   \n",
       "28.09.2017         14.41          14.71         42.60          44.00   \n",
       "27.09.2017         14.30          14.71         42.61          43.50   \n",
       "26.09.2017         14.16          14.47         42.54          43.30   \n",
       "25.09.2017         14.26          14.40         43.70          43.70   \n",
       "22.09.2017         14.30          14.40         42.25          44.00   \n",
       "21.09.2017         14.34          14.46         42.10          43.99   \n",
       "20.09.2017         14.26          14.50         42.12          42.38   \n",
       "19.09.2017         14.26          14.45         41.99          43.00   \n",
       "18.09.2017         14.20          14.52         41.92          42.50   \n",
       "15.09.2017         14.17          14.43         41.40          42.97   \n",
       "14.09.2017         14.31          14.42         41.30          42.49   \n",
       "13.09.2017         14.25          14.49         41.50          42.22   \n",
       "12.09.2017         14.11          14.49         41.29          42.28   \n",
       "11.09.2017         13.65          14.57         41.40          42.28   \n",
       "08.09.2017         13.46          13.97         40.58          42.79   \n",
       "07.09.2017         13.40          13.61         39.43          41.65   \n",
       "06.09.2017         13.39          13.54         39.42          41.81   \n",
       "05.09.2017         13.58          13.64         39.41          39.97   \n",
       "...                  ...            ...           ...            ...   \n",
       "10.07.2017         15.59          15.85         43.23          45.00   \n",
       "07.07.2017         15.61          15.84         43.38          43.94   \n",
       "06.07.2017         15.72          15.92         43.03          44.00   \n",
       "05.07.2017         15.78          15.98         43.38          44.00   \n",
       "04.07.2017         15.77          16.06         43.05          43.99   \n",
       "03.07.2017         15.93          16.05         43.10          43.66   \n",
       "30.06.2017         15.72          16.08         43.54          43.66   \n",
       "29.06.2017         15.81          16.10         43.00          44.26   \n",
       "28.06.2017         15.95          16.32         43.65          44.61   \n",
       "27.06.2017         15.97          16.34         44.10          44.00   \n",
       "26.06.2017         16.18          16.32         44.00          44.75   \n",
       "22.06.2017         16.28          16.60         43.74          45.06   \n",
       "21.06.2017         16.22          16.67         43.78          44.89   \n",
       "20.06.2017         16.40          16.48         43.65          45.40   \n",
       "19.06.2017         16.56          16.66         43.53          45.00   \n",
       "16.06.2017         16.17          16.75         43.20          44.75   \n",
       "15.06.2017         16.13          16.67         43.61          46.00   \n",
       "14.06.2017         16.04          16.44         45.04          46.00   \n",
       "13.06.2017         15.84          16.40         44.67          46.79   \n",
       "12.06.2017         15.75          16.20         45.20          46.71   \n",
       "09.06.2017         15.80          16.02         46.80          46.55   \n",
       "08.06.2017         15.72          16.01         47.00          47.53   \n",
       "07.06.2017         15.69          16.00         47.00          47.60   \n",
       "06.06.2017         15.76          16.05         47.01          48.15   \n",
       "05.06.2017         16.02          16.15         46.80          48.00   \n",
       "02.06.2017         16.10          16.32         46.57          47.90   \n",
       "01.06.2017         15.81          16.30         45.00          48.55   \n",
       "31.05.2017         15.66          16.29         44.65          46.70   \n",
       "30.05.2017         15.41          15.98         44.02          47.48   \n",
       "29.05.2017         15.26          16.13         43.50          44.85   \n",
       "\n",
       "                WÃ¤rtsilÃ¤                          YIT                 \n",
       "           sales_low_000 sales_high_001 sales_low_000 sales_high_001  \n",
       "16.10.2017         60.35          62.30          7.04           7.08  \n",
       "13.10.2017         59.30          62.00          7.02           7.14  \n",
       "12.10.2017         58.75          60.75          7.04           7.10  \n",
       "11.10.2017         58.95          59.40          7.10           7.14  \n",
       "10.10.2017         59.00          59.60          7.10           7.14  \n",
       "09.10.2017         58.85          59.50          7.08           7.16  \n",
       "06.10.2017         58.60          59.65          7.14           7.18  \n",
       "05.10.2017         60.45          59.75          7.09           7.29  \n",
       "04.10.2017         60.60          61.00          6.94           7.24  \n",
       "03.10.2017         60.05          61.30          6.98           7.06  \n",
       "02.10.2017         59.70          60.95          6.90           7.02  \n",
       "29.09.2017         59.10          60.25          6.88           6.98  \n",
       "28.09.2017         59.45          59.95          6.91           6.93  \n",
       "27.09.2017         58.85          59.90          6.90           6.99  \n",
       "26.09.2017         58.45          59.80          6.89           6.94  \n",
       "25.09.2017         58.60          59.40          6.90           6.93  \n",
       "22.09.2017         58.90          59.75          6.93           7.01  \n",
       "21.09.2017         59.30          59.75          6.94           6.97  \n",
       "20.09.2017         59.30          59.85          6.93           7.01  \n",
       "19.09.2017         58.85          59.80          6.96           7.01  \n",
       "18.09.2017         57.85          59.95          6.94           7.05  \n",
       "15.09.2017         57.55          59.00          6.94           7.04  \n",
       "14.09.2017         57.65          58.15          7.00           7.08  \n",
       "13.09.2017         57.30          58.10          7.04           7.08  \n",
       "12.09.2017         58.25          58.25          7.02           7.12  \n",
       "11.09.2017         58.35          59.20          7.02           7.16  \n",
       "08.09.2017         57.40          59.10          7.28           7.28  \n",
       "07.09.2017         56.40          58.20          7.30           7.34  \n",
       "06.09.2017         57.50          57.70          7.28           7.35  \n",
       "05.09.2017         57.70          57.95          7.29           7.39  \n",
       "...                  ...            ...           ...            ...  \n",
       "10.07.2017         52.45          54.30          7.28           7.39  \n",
       "07.07.2017         52.45          54.05          7.25           7.38  \n",
       "06.07.2017         52.10          53.10          7.22           7.35  \n",
       "05.07.2017         52.50          53.00          7.26           7.38  \n",
       "04.07.2017         52.35          53.35          7.24           7.36  \n",
       "03.07.2017         52.00          52.80          7.30           7.36  \n",
       "30.06.2017         51.50          53.10          7.16           7.42  \n",
       "29.06.2017         51.75          52.05          7.18           7.33  \n",
       "28.06.2017         52.45          53.25          7.22           7.39  \n",
       "27.06.2017         53.10          53.15          7.25           7.36  \n",
       "26.06.2017         54.05          54.40          7.28           7.37  \n",
       "22.06.2017         53.95          54.65          7.22           7.38  \n",
       "21.06.2017         54.45          54.60          7.28           7.36  \n",
       "20.06.2017         54.90          55.00          7.44           7.52  \n",
       "19.06.2017         55.35          55.85          7.66           7.93  \n",
       "16.06.2017         52.50          55.85          7.46           8.08  \n",
       "15.06.2017         52.60          55.30          7.40           7.55  \n",
       "14.06.2017         53.30          53.30          7.58           7.60  \n",
       "13.06.2017         52.75          53.95          7.49           7.68  \n",
       "12.06.2017         52.35          53.50          7.46           7.58  \n",
       "09.06.2017         52.95          53.70          7.50           7.59  \n",
       "08.06.2017         52.25          53.70          7.48           7.60  \n",
       "07.06.2017         53.10          53.45          7.48           7.58  \n",
       "06.06.2017         53.00          53.50          7.54           7.64  \n",
       "05.06.2017         53.15          53.60          7.58           7.62  \n",
       "02.06.2017         53.95          54.25          7.60           7.68  \n",
       "01.06.2017         52.95          54.65          7.52           7.68  \n",
       "31.05.2017         52.45          55.15          7.44           7.72  \n",
       "30.05.2017         52.45          53.05          7.61           7.64  \n",
       "29.05.2017         52.80          53.05          7.59           7.73  \n",
       "\n",
       "[100 rows x 366 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal parameters:\n",
    "key = 'rf'\n",
    "#opm_params = np.load('opm_params_{}.npy'.format(key)).item()\n",
    "\n",
    "def get_predictions(ntest, comp, col):\n",
    "    \n",
    "    X, y, ysim = comp_dict[comp]\n",
    "    print(X)\n",
    "    X = X[cols_keep]\n",
    "    \n",
    "    y_bin = opm_params[comp][col]['threshold'] < y[col]    \n",
    "    X_test, y_test = X[:ntest], y_bin[:ntest]\n",
    "    X_train, y_train = X[ntest:], y_bin[ntest:]\n",
    "    \n",
    "    pipe, _ = get_pipe(key)\n",
    "    pipe.set_params(**opm_params[comp][col]['opm_params']) \n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    return pipe.predict(X_test)\n",
    "\n",
    "def get_prediction_df(ntest):\n",
    "    idx_tuples = [(comp, col) for comp in companies for col in y.columns]\n",
    "    index = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "    \n",
    "    \n",
    "    pred_df = pd.DataFrame(index = comp_dict['Alma Media'][0].index[:ntest], columns = index)\n",
    "    \n",
    "    for comp in companies:\n",
    "        ysim = comp_dict[comp][-1]\n",
    "\n",
    "        for col in y.columns:\n",
    "            pred_df[(comp, col)] = np.zeros(ntest) #get_predictions(ntest, comp, col)\n",
    "        \n",
    "        pred_df[(comp, 'sales_low_000')] = ysim['sales_low_000']\n",
    "        pred_df[(comp, 'sales_high_{:03d}'.format(nfut-1))] = ysim['sales_high_{:03d}'.format(nfut-1)]\n",
    "    pred_df.index = comp_dict[comp][0].index.values[:ntest]\n",
    "    return pred_df\n",
    "\n",
    "get_prediction_df(100) #['Aktia Pankki A']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
