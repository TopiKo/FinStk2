{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from df_utils import get_companies_list, get_X_y\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, \\\n",
    "                            precision_score, accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataframe and companies with not too many nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, companies = get_companies_list(2)\n",
    "# learner history parameters\n",
    "nhist = 10\n",
    "nfut = 2\n",
    "totHist = int(3*365 - nhist)\n",
    "\n",
    "comp_dict = {}\n",
    "for i, comp in enumerate(companies):\n",
    "    comp_dict[comp] = get_X_y(df, comp, nfut, nhist, totHist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop some columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['offer_end_-01' 'offer_end_-02' 'offer_end_-03' 'offer_end_-04'\n",
      " 'offer_end_-05' 'offer_end_-06' 'offer_end_-07' 'offer_end_-08'\n",
      " 'offer_end_-09' 'offer_end_-10' 'offer_buy_-01' 'offer_buy_-02'\n",
      " 'offer_buy_-03' 'offer_buy_-04' 'offer_buy_-05' 'offer_buy_-06'\n",
      " 'offer_buy_-07' 'offer_buy_-08' 'offer_buy_-09' 'offer_buy_-10'\n",
      " 'offer_sell_-01' 'offer_sell_-02' 'offer_sell_-03' 'offer_sell_-04'\n",
      " 'offer_sell_-05' 'offer_sell_-06' 'offer_sell_-07' 'offer_sell_-08'\n",
      " 'offer_sell_-09' 'offer_sell_-10' 'sales_low_-01' 'sales_low_-02'\n",
      " 'sales_low_-03' 'sales_low_-04' 'sales_low_-05' 'sales_low_-06'\n",
      " 'sales_low_-07' 'sales_low_-08' 'sales_low_-09' 'sales_low_-10'\n",
      " 'sales_high_-01' 'sales_high_-02' 'sales_high_-03' 'sales_high_-04'\n",
      " 'sales_high_-05' 'sales_high_-06' 'sales_high_-07' 'sales_high_-08'\n",
      " 'sales_high_-09' 'sales_high_-10' 'change_Me_-01' 'change_Me_-02'\n",
      " 'change_Me_-03' 'change_Me_-04' 'change_Me_-05' 'change_Me_-06'\n",
      " 'change_Me_-07' 'change_Me_-08' 'change_Me_-09' 'change_Me_-10'\n",
      " 'c_slow_-01' 'c_slow_-02' 'c_slow_-03' 'c_slow_-04' 'c_slow_-05'\n",
      " 'c_slow_-06' 'c_slow_-07' 'c_slow_-08' 'c_slow_-09' 'c_slow_-10'\n",
      " 'c_slow_%_-01' 'c_slow_%_-02' 'c_slow_%_-03' 'c_slow_%_-04' 'c_slow_%_-05'\n",
      " 'c_slow_%_-06' 'c_slow_%_-07' 'c_slow_%_-08' 'c_slow_%_-09' 'c_slow_%_-10'\n",
      " 'c_shigh_-01' 'c_shigh_-02' 'c_shigh_-03' 'c_shigh_-04' 'c_shigh_-05'\n",
      " 'c_shigh_-06' 'c_shigh_-07' 'c_shigh_-08' 'c_shigh_-09' 'c_shigh_-10'\n",
      " 'c_shigh_%_-01' 'c_shigh_%_-02' 'c_shigh_%_-03' 'c_shigh_%_-04'\n",
      " 'c_shigh_%_-05' 'c_shigh_%_-06' 'c_shigh_%_-07' 'c_shigh_%_-08'\n",
      " 'c_shigh_%_-09' 'c_shigh_%_-10' 'c_oend_-01' 'c_oend_-02' 'c_oend_-03'\n",
      " 'c_oend_-04' 'c_oend_-05' 'c_oend_-06' 'c_oend_-07' 'c_oend_-08'\n",
      " 'c_oend_-09' 'c_oend_-10' 'c_oend_%_-01' 'c_oend_%_-02' 'c_oend_%_-03'\n",
      " 'c_oend_%_-04' 'c_oend_%_-05' 'c_oend_%_-06' 'c_oend_%_-07' 'c_oend_%_-08'\n",
      " 'c_oend_%_-09' 'c_oend_%_-10']\n",
      "['offer_end_change' 'sale_low_change+1' 'sale_low_change'\n",
      " 'sale_high_change']\n",
      "['sales_low_prev' 'sales_high_prev' 'sale_low_change+1' 'sale_low_change'\n",
      " 'offer_end_prev' 'sales_low_000' 'sales_high_000' 'sales_low_001'\n",
      " 'sales_high_001' 'offer_end_001']\n"
     ]
    }
   ],
   "source": [
    "X_orig, y, ysim = comp_dict[comp]\n",
    "print(X_orig.columns.values)\n",
    "print(y.columns.values)\n",
    "print(ysim.columns.values)\n",
    "\n",
    "include = ['c_oend_%', 'c_slow_%', 'c_shigh_%', 'change_Me', 'offer_sell_', 'offer_buy_'] #['c_shigh_', 'c_slow_', 'offer_sell_', 'offer_buy_', 'sales_low_', 'sales_high_']\n",
    "cols_keep = [col for col in X_orig.columns if col[:-4] in include] \n",
    "y_cols = ['offer_end_change', 'sale_low_change', 'sale_high_change']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot pictures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_sim(comp, ysim, ndays, *args):\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize = (12,6))\n",
    "    x = pd.to_datetime(ysim.index, format = '%d.%m.%Y')[:ndays]\n",
    "    yl = ysim['sales_low_000'].values[:ndays]\n",
    "    yh = ysim['sales_high_000'].values[:ndays]\n",
    "    #y = ysim['offer_end_prev'].values[:ndays]\n",
    "    \n",
    "    #plt.plot_date(x,y, linestyle = '-', marker = None)\n",
    "    plt.fill_between(x,yl,yh, linestyle = '-')\n",
    "    plt.ylabel('Sales lowest to highest filled')\n",
    "    #[plt.gca().axvline(xi, alpha = .1) for xi in x]\n",
    "    \n",
    "    if len(args) == 3:\n",
    "        pred, truth, col = [arg[:ndays] for arg in args]\n",
    "        \n",
    "        correct = pred & truth\n",
    "        fp = pred & np.logical_not(truth)\n",
    "        \n",
    "        plt.scatter(x[correct], yh[correct], s = 40, alpha = .7, \n",
    "                    c = 'green', label = col + ' correct')\n",
    "        plt.scatter(x[truth], yh[truth], s = 20, c = 'red', alpha = .2,\n",
    "                    label = col + ' true')\n",
    "        \n",
    "    else:    \n",
    "        plt.twinx()\n",
    "        y2 = ysim['offer_end_change']*100\n",
    "        plt.plot_date(x,y2, linestyle = '-', marker = None, color = 'red')\n",
    "        plt.ylabel('Offer end percentage change')\n",
    "    \n",
    "    plt.legend(frameon = False)\n",
    "    plt.title(comp, fontsize = 14)\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make estimator pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([('pol', PolynomialFeatures(degree = 2, interaction_only = True)),\n",
    "                    ('var', VarianceThreshold()),\n",
    "                    ('sel', SelectKBest()),\n",
    "                    ('rf', RandomForestClassifier())]) \n",
    "\n",
    "params_rf = [{'sel__k': np.arange(40,100,10),\n",
    "              'rf__max_features': np.arange(5,30,5),\n",
    "              'rf__max_depth': [5,10,20],\n",
    "              'rf__n_estimators': [20,50,100]}]\n",
    "\n",
    "pipe_gbm = Pipeline([('pol', PolynomialFeatures(degree = 2, interaction_only = True)),\n",
    "                     ('var', VarianceThreshold()),\n",
    "                     ('sel', SelectKBest()),\n",
    "                     ('gbm', GradientBoostingClassifier())]) \n",
    "\n",
    "params_gbm = [{'sel__k': np.arange(20,50,10),\n",
    "               'gbm__learning_rate': np.linspace(.05,.4, 8),\n",
    "               'gbm__max_depth': [3,5],\n",
    "               'gbm__n_estimators': np.arange(50, 200, 25) }]\n",
    "\n",
    "\n",
    "def get_pipe(key):\n",
    "    if key == 'rf':\n",
    "        return pipe_rf, params_rf\n",
    "    elif key == 'gbm':\n",
    "        return pipe_gbm, params_gbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make custom fit for each company:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_estimator(comp, y, threshold, pipe, params, ntest = 50, metric = 'roc_auc'):\n",
    "    \n",
    "    splitter = StratifiedKFold(n_splits = 5, shuffle = True) #, random_state = 0)\n",
    "    X,_,ysim = comp_dict[comp]\n",
    "    X = X[cols_keep]\n",
    "    \n",
    "    y_bin = threshold < y\n",
    "    \n",
    "    X_test, y_test = X[:ntest], y_bin[:ntest]\n",
    "    X_train, y_train = X[ntest:], y_bin[ntest:]\n",
    "    Xy = [X_train, X_test, y_train, y_test, ysim, y_bin]\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(pipe, params, scoring = metric, n_jobs = 5, \n",
    "                        cv = splitter, verbose = 1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return Xy, grid.best_estimator_, grid.best_params_, grid.best_score_\n",
    "\n",
    "\n",
    "def get_scores(y_pred_train, y_pred_test, y_pred_train_p, \n",
    "               y_pred_test_p, y_train, y_test, show_report = False):\n",
    "    try:\n",
    "        roc_auc_test = roc_auc_score(y_test, y_pred_test_p)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        roc_auc_test = -1\n",
    "    \n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    \n",
    "    if show_report:\n",
    "        print('Train set classification')\n",
    "        print(classification_report(y_train, y_pred_train, target_names = ['not rise', 'rise']))\n",
    "        print(confusion_matrix(y_train, y_pred_train))\n",
    "        print('Train roc_auc = {:.3f}'.format(roc_auc_score(y_train, y_pred_train_p)))\n",
    "        print('\\nTest set classification')\n",
    "        print(classification_report(y_test, y_pred_test, target_names = ['not rise', 'rise']))\n",
    "        print(confusion_matrix(y_test, y_pred_test))\n",
    "        print('Test roc_auc = {:.3f}\\n'.format(roc_auc_test))\n",
    "    \n",
    "    return roc_auc_test, precision_test\n",
    "\n",
    "def get_prediction(Xy, estimator, show_report = False):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Xy[:4]\n",
    "    y_pred_train = estimator.predict(X_train)\n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "    y_pred_train_p = estimator.predict_proba(X_train)[:,1]\n",
    "    y_pred_test_p = estimator.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    \n",
    "    return y_pred_train, y_pred_test, y_pred_train_p, y_pred_test_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed the pipe to fit for each company and collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_report(companies, key = 'rf', ntest = 100, show = False):\n",
    "    \n",
    "    thres = {'offer_end_change':.0, \n",
    "             'sale_low_change+1':.0,\n",
    "             'sale_low_change':.0,\n",
    "             'sale_high_change':.0}\n",
    "    \n",
    "    pipe, params = get_pipe(key)\n",
    "    \n",
    "    try:\n",
    "        results_dict = np.load('opm_params_{}.npy'.format(key)).item()        \n",
    "    except FileNotFoundError:\n",
    "        results_dict = {}\n",
    "    \n",
    "    for comp in companies:\n",
    "        y = comp_dict[comp][1]\n",
    "        for col in y.columns.values:\n",
    "            try:\n",
    "                results_dict[comp][col]\n",
    "            except KeyError:\n",
    "                \n",
    "                \n",
    "                print(comp, ' ', col)\n",
    "\n",
    "                X,_,ysim = comp_dict[comp]\n",
    "                X = X[cols_keep]\n",
    "\n",
    "                Xy, estimator_r, params_opm_r, score_r \\\n",
    "                    = comp_estimator(comp, y[col].values,\n",
    "                                     thres[col], pipe, params,\n",
    "                                     ntest = ntest,\n",
    "                                     metric = 'roc_auc')\n",
    "\n",
    "                y_pred_train, y_pred_test, y_pred_train_p, y_pred_test_p \\\n",
    "                    = get_prediction(Xy, estimator_r)\n",
    "\n",
    "                roc_auc, precision = get_scores(y_pred_train, \n",
    "                                                y_pred_test, \n",
    "                                                y_pred_train_p, \n",
    "                                                y_pred_test_p, \n",
    "                                                Xy[2], Xy[3], \n",
    "                                                show_report = show)\n",
    "\n",
    "                if show:\n",
    "                    print(params_opm_r)\n",
    "                    y_pred_tot = np.concatenate((y_pred_test, \n",
    "                                                 y_pred_train))\n",
    "                    plot_sim(comp, Xy[4], ntest*4, y_pred_tot, \n",
    "                             Xy[5], col)\n",
    "\n",
    "\n",
    "                col_dict = {col: {'roc_auc':roc_auc, \n",
    "                                  'precision':precision,\n",
    "                                  'threshold':thres[col],\n",
    "                                  'opm_params':params_opm_r}}\n",
    "                try:\n",
    "                    results_dict[comp].update(col_dict)\n",
    "                except KeyError:\n",
    "                    results_dict[comp] = col_dict\n",
    "                 \n",
    "                np.save('opm_params_{}'.format(key), results_dict)\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Affecto', 'Ahlstrom-Munksjö', 'Aktia Pankki A', 'Alma Media', 'Amer Sports A', 'Apetit', 'Aspo', 'Atria A', 'Basware', 'Biohit B', 'Bittium', 'CapMan', 'Cargotec', 'Caverion', 'Citycon', 'Cramo', 'Digia', 'Elisa', 'F-Secure', 'Finnair', 'Fiskars', 'Fortum', 'Glaston', 'HKScan A', 'Huhtamäki', 'Kemira', 'Kesko A', 'Kesko B', 'Kone', 'Konecranes', 'Lassila & Tikanoja', 'Lemminkäinen', 'Marimekko', 'Metso', 'Metsä Board A', 'Metsä Board B', 'Neste', 'Nokia', 'Nokian Renkaat', 'Nordea Bank', 'OMXH25 ETF', 'Olvi A', 'Oriola B', 'Orion A', 'Orion B', 'Outokumpu', 'Outotec', 'Panostaja', 'Ponsse', 'Pöyry', 'Raisio V', 'Ramirent', 'Revenio Group', 'SRV Yhtiöt', 'SSH Comm. Security', 'Saga Furs C', 'Sampo A', 'Sanoma', 'Scanfil', 'Stockmann A', 'Stockmann B', 'Stora Enso A', 'Stora Enso R', 'Suominen', 'Technopolis', 'Tecnotree', 'Teleste', 'Telia Company', 'Tieto', 'Tikkurila', 'Tulikivi A', 'UPM-Kymmene', 'Uponor', 'Vaisala A', 'Valoe', 'Wärtsilä', 'YIT', 'Ålandsbanken B']\n",
      "Affecto   offer_end_change\n",
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e7fe97259675>\u001b[0m in \u001b[0;36mfit_and_report\u001b[0;34m(companies, key, ntest, show)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Affecto'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5f82c4fabdab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmethod_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompanies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_and_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompanies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-e7fe97259675>\u001b[0m in \u001b[0;36mfit_and_report\u001b[0;34m(companies, key, ntest, show)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                      \u001b[0mthres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                      \u001b[0mntest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                      metric = 'roc_auc')\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test_p\u001b[0m                     \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-3feac741d67b>\u001b[0m in \u001b[0;36mcomp_estimator\u001b[0;34m(comp, y, threshold, pipe, params, ntest, metric)\u001b[0m\n\u001b[1;32m     14\u001b[0m     grid = GridSearchCV(pipe, params, scoring = metric, n_jobs = 5, \n\u001b[1;32m     15\u001b[0m                         cv = splitter, verbose = 1)\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "method_key = 'gbm'\n",
    "print(companies)\n",
    "results_dict = fit_and_report(companies, method_key, ntest = 70, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then test the obtained results:\n",
    "### First make the prediction dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimal parameters:\n",
    "opm_params = np.load('opm_params_{}.npy'.format(method_key)).item()\n",
    "\n",
    "\n",
    "def get_predictions(ntest, comp, col):\n",
    "    \n",
    "    X, y, ysim = comp_dict[comp]\n",
    "    X = X[cols_keep]\n",
    "    \n",
    "    y_bin = opm_params[comp][col]['threshold'] < y[col]    \n",
    "    X_test, y_test = X[:ntest], y_bin[:ntest]\n",
    "    X_train, y_train = X[ntest:], y_bin[ntest:]\n",
    "    \n",
    "    pipe, _ = get_pipe(method_key)\n",
    "    pipe.set_params(**opm_params[comp][col]['opm_params']) \n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    return pipe.predict(X_test)\n",
    "\n",
    "def get_prediction_df(ntest):\n",
    "    idx_tuples = [(comp, col) for comp in companies for col in y.columns]\n",
    "    index = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "    \n",
    "    \n",
    "    pred_df = pd.DataFrame(index = comp_dict['Alma Media'][0].index[:ntest], columns = index)\n",
    "    \n",
    "    for comp in companies:\n",
    "        ysim = comp_dict[comp][-1]\n",
    "\n",
    "        for col in y.columns:\n",
    "            pred_df[(comp, col)] = get_predictions(ntest, comp, col) #np.zeros(ntest)\n",
    "        \n",
    "        pred_df[(comp, 'sales_low_prev')] = ysim['sales_low_prev']\n",
    "        pred_df[(comp, 'sales_high_prev')] = ysim['sales_high_prev']\n",
    "        \n",
    "        pred_df[(comp, 'sales_low_000'.format(nfut-1))] = ysim['sales_low_000'.format(nfut-1)]\n",
    "        pred_df[(comp, 'sales_high_{:03d}'.format(nfut-1))] = ysim['sales_high_{:03d}'.format(nfut-1)]\n",
    "        pred_df[(comp, 'offer_end_{:03d}'.format(nfut-1))] = ysim['offer_end_{:03d}'.format(nfut-1)]\n",
    "    pred_df.index = comp_dict[comp][0].index.values[:ntest]\n",
    "    return pred_df\n",
    "\n",
    "df_pred = get_prediction_df(100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bought Elisa price=34.76\n",
      "Sold Elisa price=34.95\n",
      "\n",
      "Bought Neste price=34.27\n",
      "Sold Neste price=34.75\n",
      "\n",
      "Bought Elisa price=33.72\n",
      "Bought Neste price=34.45\n",
      "Sold Elisa price=33.74\n",
      "Sold Neste price=34.96\n",
      "\n",
      "Bought Elisa price=34.91\n",
      "Sold Elisa price=34.78\n",
      "\n",
      "Bought Elisa price=34.63\n",
      "Sold Elisa price=34.81\n",
      "\n",
      "Bought Neste price=36.83\n",
      "Bought Elisa price=34.68\n",
      "Sold Neste price=37.00\n",
      "\n",
      "Sold Elisa price=35.16\n",
      "\n",
      "Bought Neste price=34.68\n",
      "Sold Neste price=35.00\n",
      "\n",
      "Bought Elisa price=36.06\n",
      "Sold Elisa price=36.01\n",
      "\n",
      "Bought Elisa price=35.90\n",
      "Sold Elisa price=36.04\n",
      "\n",
      "Bought Elisa price=35.71\n",
      "Sold Elisa price=36.11\n",
      "\n",
      "Bought Neste price=36.12\n",
      "Sold Neste price=36.19\n",
      "\n",
      "Bought Neste price=36.15\n",
      "Sold Neste price=35.97\n",
      "\n",
      "Bought Neste price=35.95\n",
      "Sold Neste price=36.26\n",
      "\n",
      "Bought Neste price=37.39\n",
      "Sold Neste price=36.89\n",
      "\n",
      "Bought Elisa price=36.46\n",
      "Bought Neste price=37.44\n",
      "Sold Elisa price=36.81\n",
      "Sold Neste price=37.82\n",
      "\n",
      "Bought Elisa price=36.63\n",
      "Sold Elisa price=36.44\n",
      "\n",
      "Money in end: 10328.380000\n"
     ]
    }
   ],
   "source": [
    "def simulate(pred_df, marginal = 1.5, roc_thres = .6, dealer = 0.):\n",
    "    \n",
    "    shop_df = pd.DataFrame(columns = ['index','day','comp','nstock', 'buy', 'sell'])\n",
    "    shop_df.set_index(['index','day', 'comp'], inplace = True)\n",
    "    \n",
    "    # Defines the condition when stock is bought\n",
    "    buy_condition = {'sale_low_change+1':False, 'sale_high_change':True} #\n",
    "    free_money = 1e4\n",
    "    action = False\n",
    "    for i, day in enumerate(df_pred.index[::-1]):\n",
    "        basket = []\n",
    "        for comp in companies:\n",
    "            can_shop = False\n",
    "            # Condition to buy:\n",
    "            if all([pred_df.loc[day, comp][key] == val for key,val in buy_condition.items()]) and \\\n",
    "                i+2 < len(df_pred):\n",
    "                # Make sure today sale low is smaller than yesterday:\n",
    "                if pred_df.loc[day, comp]['sales_low_000'] < pred_df.loc[day, comp]['sales_low_prev']:\n",
    "                    buy_price = pred_df.loc[day, comp]['sales_low_prev']\n",
    "                    \n",
    "                    if buy_price*(1+marginal/100.) \\\n",
    "                    < pred_df.loc[day, comp]['sales_high_{:03d}'.format(nfut-1)]: \n",
    "                        sell_price = buy_price*(1+marginal/100.)\n",
    "                    else:\n",
    "                        sell_price = pred_df.loc[day, comp]['offer_end_{:03d}'.format(nfut-1)]\n",
    "                        \n",
    "                    \n",
    "                    can_shop = True\n",
    "            if can_shop:\n",
    "                basket.append((comp, buy_price, sell_price))\n",
    "        \n",
    "        for scomp, buy, sell in basket:\n",
    "            buy_roc = opm_params[scomp]['sale_low_change+1']['roc_auc']\n",
    "            sell_roc = opm_params[scomp]['sale_high_change']['roc_auc']\n",
    "            if (roc_thres < np.array([buy_roc, sell_roc])).all():\n",
    "                n_stock = int(free_money/2/buy)\n",
    "                free_money -= n_stock*buy  + dealer\n",
    "                shop_df.loc[(i, day, scomp), ['nstock', 'buy', 'sell']] = n_stock, buy, sell \n",
    "                action = True\n",
    "                print('Bought {} price={:.02f}'.format(scomp, buy))\n",
    "        if action:\n",
    "            # Time to sell:\n",
    "            if i-1 in list(zip(*shop_df.index.values))[0]:\n",
    "                for idx in [idx for idx in shop_df.index.values if idx[0] == i-1]:\n",
    "                    n, price = shop_df.loc[idx][['nstock', 'sell']]\n",
    "                    free_money += n*price - dealer\n",
    "                    print('Sold {} price={:.02f}'.format(idx[2], price))\n",
    "                print()\n",
    "    print('Money in end: {:0f}'.format(free_money))\n",
    "    \n",
    "simulate(df_pred, 100, .65)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
